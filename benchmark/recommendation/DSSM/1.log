nohup: ignoring input
Init argument: Convert 1 (<class 'int'>) to 1.0 (<class 'float'>).
Init argument: Convert 50 (<class 'int'>) to 50.0 (<class 'float'>).
Init argument: Convert 10000 (<class 'int'>) to 10000.0 (<class 'float'>).
self.data_args: DataArguments(train_data=None, eval_data=None, data_cache_dir=None, cache_path=None, name='recflow', type='hdfs', url='hdfs://node1:8020/recstudio/recflow/realshow', file_partition={'type': 'date', 'format': '%Y-%m-%d'}, labels=['effective_view'], stats=Statistics(columns=['user_id', 'device_id', 'age', 'gender', 'province', 'video_id', 'author_id', 'category_level_one', 'category_level_two', 'upload_type']), item_col='video_id', context_features=['user_id', 'device_id', 'age', 'gender', 'province'], item_features=['video_id', 'author_id', 'category_level_two', 'upload_type', 'category_level_one'], item_batch_size=2048, files=None, train_period={'start_date': '2024-01-13', 'end_date': '2024-02-18'}, test_period={'start_date': '2024-02-18', 'end_date': '2024-02-19'}, user_sequential_info=[{'name': 'user_seq_effective_50', 'url': 'hdfs://node1:8020/recstudio/recflow/seq_effective_50', 'key': 'request_id', 'columns': ['video_id', 'author_id', 'category_level_two', 'category_level_one', 'upload_type', 'upload_timestamp', 'duration', 'request_timestamp', 'playing_time', 'request_id'], 'use_cols': ['video_id', 'author_id', 'category_level_two', 'category_level_one', 'upload_type'], 'length': 50}], post_process=None, filter_settings={'effective_view': ['==1']}, item_info={'url': 'hdfs://node1:8020/recstudio/recflow/others/video_info.pkl', 'key': 'video_id', 'columns': ['video_id', 'author_id', 'category_level_two', 'upload_type', 'upload_timestamp', 'category_level_one'], 'use_cols': ['video_id', 'author_id', 'category_level_two', 'upload_type', 'category_level_one']}, seq_features=None)
SASRecRetriever(
  (loss_function): BinaryCrossEntropyLoss()
  (score_function): InnerProductScorer()
  (item_encoder): MultiFeatEmbedding(
    (feat2embedding): ModuleDict(
      (video_id): Embedding(82216301, 2, padding_idx=0)
      (author_id): Embedding(33474011, 2, padding_idx=0)
      (category_level_two): Embedding(784, 2, padding_idx=0)
      (upload_type): Embedding(40, 2, padding_idx=0)
      (category_level_one): Embedding(140, 2, padding_idx=0)
    )
  )
  (query_encoder): Sequential(
    (encoder): SASRecEncoder(
      (item_encoder): MultiFeatEmbedding(
        (feat2embedding): ModuleDict(
          (video_id): Embedding(82216301, 2, padding_idx=0)
          (author_id): Embedding(33474011, 2, padding_idx=0)
          (category_level_two): Embedding(784, 2, padding_idx=0)
          (upload_type): Embedding(40, 2, padding_idx=0)
          (category_level_one): Embedding(140, 2, padding_idx=0)
        )
      )
      (context_embedding): MultiFeatEmbedding(
        (feat2embedding): ModuleDict(
          (user_id): Embedding(42472, 2, padding_idx=0)
          (device_id): Embedding(42561, 2, padding_idx=0)
          (age): Embedding(8, 2, padding_idx=0)
          (gender): Embedding(3, 2, padding_idx=0)
          (province): Embedding(79, 2, padding_idx=0)
        )
      )
      (seq_aggragation): ModuleDict(
        (user_seq_effective_50): SelfAttentiveAggregator(
          input_dim=10, n_layers=1, n_heads=2, hidden_dim=64, dropout=0.3
          (transformer_encoder): TransformerEncoder(
            (layers): ModuleList(
              (0): TransformerEncoderLayer(
                (self_attn): MultiheadAttention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)
                )
                (linear1): Linear(in_features=10, out_features=64, bias=True)
                (dropout): Dropout(p=0.3, inplace=False)
                (linear2): Linear(in_features=64, out_features=10, bias=True)
                (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
                (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
                (dropout1): Dropout(p=0.3, inplace=False)
                (dropout2): Dropout(p=0.3, inplace=False)
              )
            )
          )
          (position_embedding): Embedding(50, 10)
          (seq_aggragation): LastItemAggregator(dim=1)
        )
      )
    )
    (mlp): MLPModule(
      (model): Sequential(
        (0): Dropout(p=0.3, inplace=False)
        (1): Linear(in_features=20, out_features=64, bias=True)
        (2): ReLU()
        (3): Dropout(p=0.3, inplace=False)
        (4): Linear(in_features=64, out_features=8, bias=True)
        (5): ReLU()
        (6): Dropout(p=0.3, inplace=False)
        (7): Linear(in_features=8, out_features=10, bias=True)
      )
    )
  )
)
[2025-02-06 23:56:07,817] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Load dataset file 2024-01-13.feather from cache
Load dataset sucessfully.
Step 50: {'loss': 1.2987, 'grad_norm': 0.063633, 'learning_rate': 0.099997, 'epoch': 1}
Step 100: {'loss': 1.2427, 'grad_norm': 0.112424, 'learning_rate': 0.099995, 'epoch': 1}
Step 150: {'loss': 1.1936, 'grad_norm': 0.106363, 'learning_rate': 0.099992, 'epoch': 1}
Step 200: {'loss': 1.1558, 'grad_norm': 0.128341, 'learning_rate': 0.09999, 'epoch': 1}
Step 250: {'loss': 1.122, 'grad_norm': 0.513597, 'learning_rate': 0.099987, 'epoch': 1}
Step 300: {'loss': 1.0871, 'grad_norm': 0.407359, 'learning_rate': 0.099985, 'epoch': 1}
Step 350: {'loss': 1.0671, 'grad_norm': 0.677128, 'learning_rate': 0.099982, 'epoch': 1}
Step 400: {'loss': 1.0512, 'grad_norm': 0.655042, 'learning_rate': 0.09998, 'epoch': 1}
Step 450: {'loss': 1.0172, 'grad_norm': 0.870229, 'learning_rate': 0.099977, 'epoch': 1}
Step 500: {'loss': 0.9989, 'grad_norm': 0.290806, 'learning_rate': 0.099974, 'epoch': 1}
Step 550: {'loss': 0.9822, 'grad_norm': 0.243823, 'learning_rate': 0.099972, 'epoch': 1}
Step 600: {'loss': 0.9599, 'grad_norm': 0.208592, 'learning_rate': 0.099969, 'epoch': 1}
Step 650: {'loss': 0.9529, 'grad_norm': 0.212433, 'learning_rate': 0.099967, 'epoch': 1}
Step 700: {'loss': 0.9343, 'grad_norm': 1.012712, 'learning_rate': 0.099964, 'epoch': 1}
Step 750: {'loss': 0.9208, 'grad_norm': 0.493069, 'learning_rate': 0.099962, 'epoch': 1}
Step 800: {'loss': 0.902, 'grad_norm': 0.58539, 'learning_rate': 0.099959, 'epoch': 1}
Load dataset file 2024-01-14.feather from source
Load dataset sucessfully.
Step 850: {'loss': 1.0005, 'grad_norm': 1.569266, 'learning_rate': 0.099956, 'epoch': 1}
Step 900: {'loss': 1.0749, 'grad_norm': 2.187341, 'learning_rate': 0.099954, 'epoch': 1}
Step 950: {'loss': 1.0863, 'grad_norm': 1.410317, 'learning_rate': 0.099951, 'epoch': 1}
Step 1000: {'loss': 1.0164, 'grad_norm': 0.564432, 'learning_rate': 0.099949, 'epoch': 1}
Step 1050: {'loss': 0.9916, 'grad_norm': 0.312393, 'learning_rate': 0.099946, 'epoch': 1}
Step 1100: {'loss': 0.9801, 'grad_norm': 0.710426, 'learning_rate': 0.099944, 'epoch': 1}
Step 1150: {'loss': 0.9653, 'grad_norm': 1.372596, 'learning_rate': 0.099941, 'epoch': 1}
Step 1200: {'loss': 0.9419, 'grad_norm': 1.213278, 'learning_rate': 0.099939, 'epoch': 1}
Step 1250: {'loss': 0.9188, 'grad_norm': 0.476479, 'learning_rate': 0.099936, 'epoch': 1}
Step 1300: {'loss': 0.9103, 'grad_norm': 0.990002, 'learning_rate': 0.099933, 'epoch': 1}
Step 1350: {'loss': 0.8999, 'grad_norm': 0.702571, 'learning_rate': 0.099931, 'epoch': 1}
Step 1400: {'loss': 0.8846, 'grad_norm': 1.902911, 'learning_rate': 0.099928, 'epoch': 1}
Step 1450: {'loss': 0.8818, 'grad_norm': 0.67659, 'learning_rate': 0.099926, 'epoch': 1}
Step 1500: {'loss': 0.8845, 'grad_norm': 3.081332, 'learning_rate': 0.099923, 'epoch': 1}
Step 1550: {'loss': 0.8613, 'grad_norm': 0.812008, 'learning_rate': 0.099921, 'epoch': 1}
Step 1600: {'loss': 0.8592, 'grad_norm': 0.989358, 'learning_rate': 0.099918, 'epoch': 1}
Step 1650: {'loss': 0.8529, 'grad_norm': 0.600322, 'learning_rate': 0.099916, 'epoch': 1}
Load dataset file 2024-01-15.feather from source
Load dataset sucessfully.
Step 1700: {'loss': 1.0243, 'grad_norm': 1.46946, 'learning_rate': 0.099913, 'epoch': 1}
Step 1750: {'loss': 1.0328, 'grad_norm': 1.29653, 'learning_rate': 0.09991, 'epoch': 1}
Step 1800: {'loss': 1.0151, 'grad_norm': 0.891214, 'learning_rate': 0.099908, 'epoch': 1}
Step 1850: {'loss': 0.9982, 'grad_norm': 0.461028, 'learning_rate': 0.099905, 'epoch': 1}
Step 1900: {'loss': 1.0062, 'grad_norm': 2.466597, 'learning_rate': 0.099903, 'epoch': 1}
Step 1950: {'loss': 0.9915, 'grad_norm': 2.682793, 'learning_rate': 0.0999, 'epoch': 1}
Step 2000: {'loss': 0.9756, 'grad_norm': 5.078338, 'learning_rate': 0.099898, 'epoch': 1}
Step 2050: {'loss': 0.9521, 'grad_norm': 1.56531, 'learning_rate': 0.099895, 'epoch': 1}
Step 2100: {'loss': 0.9378, 'grad_norm': 2.905889, 'learning_rate': 0.099892, 'epoch': 1}
Step 2150: {'loss': 0.9253, 'grad_norm': 1.342099, 'learning_rate': 0.09989, 'epoch': 1}
Step 2200: {'loss': 0.9049, 'grad_norm': 0.633081, 'learning_rate': 0.099887, 'epoch': 1}
Step 2250: {'loss': 0.8919, 'grad_norm': 0.872995, 'learning_rate': 0.099885, 'epoch': 1}
Step 2300: {'loss': 0.9152, 'grad_norm': 0.924348, 'learning_rate': 0.099882, 'epoch': 1}
Step 2350: {'loss': 0.879, 'grad_norm': 1.699445, 'learning_rate': 0.09988, 'epoch': 1}
Load dataset file 2024-01-16.feather from source
Load dataset sucessfully.
Step 2400: {'loss': 0.9942, 'grad_norm': 2.153584, 'learning_rate': 0.099877, 'epoch': 1}
Step 2450: {'loss': 1.0901, 'grad_norm': 2.663367, 'learning_rate': 0.099875, 'epoch': 1}
Step 2500: {'loss': 1.0432, 'grad_norm': 2.055187, 'learning_rate': 0.099872, 'epoch': 1}
Step 2550: {'loss': 1.0014, 'grad_norm': 0.359537, 'learning_rate': 0.099869, 'epoch': 1}
Step 2600: {'loss': 0.9859, 'grad_norm': 3.057723, 'learning_rate': 0.099867, 'epoch': 1}
Step 2650: {'loss': 0.9683, 'grad_norm': 1.885397, 'learning_rate': 0.099864, 'epoch': 1}
Step 2700: {'loss': 0.974, 'grad_norm': 4.414412, 'learning_rate': 0.099862, 'epoch': 1}
Step 2750: {'loss': 0.9227, 'grad_norm': 1.339689, 'learning_rate': 0.099859, 'epoch': 1}
Step 2800: {'loss': 0.9201, 'grad_norm': 0.899636, 'learning_rate': 0.099857, 'epoch': 1}
Step 2850: {'loss': 0.8958, 'grad_norm': 2.321777, 'learning_rate': 0.099854, 'epoch': 1}
Step 2900: {'loss': 0.8916, 'grad_norm': 4.886205, 'learning_rate': 0.099852, 'epoch': 1}
Step 2950: {'loss': 0.9007, 'grad_norm': 2.077506, 'learning_rate': 0.099849, 'epoch': 1}
Step 3000: {'loss': 0.8999, 'grad_norm': 4.688159, 'learning_rate': 0.099846, 'epoch': 1}
Step 3050: {'loss': 0.8871, 'grad_norm': 5.557036, 'learning_rate': 0.099844, 'epoch': 1}
Step 3100: {'loss': 0.8712, 'grad_norm': 0.743609, 'learning_rate': 0.099841, 'epoch': 1}
Load dataset file 2024-01-17.feather from source
Load dataset sucessfully.
Step 3150: {'loss': 1.0818, 'grad_norm': 6.108245, 'learning_rate': 0.099839, 'epoch': 1}
Step 3200: {'loss': 1.052, 'grad_norm': 0.350634, 'learning_rate': 0.099836, 'epoch': 1}
Step 3250: {'loss': 1.0235, 'grad_norm': 1.331329, 'learning_rate': 0.099834, 'epoch': 1}
Step 3300: {'loss': 0.9783, 'grad_norm': 3.127828, 'learning_rate': 0.099831, 'epoch': 1}
Step 3350: {'loss': 0.9773, 'grad_norm': 3.769306, 'learning_rate': 0.099828, 'epoch': 1}
Step 3400: {'loss': 0.9725, 'grad_norm': 3.292972, 'learning_rate': 0.099826, 'epoch': 1}
Step 3450: {'loss': 0.9958, 'grad_norm': 1.652616, 'learning_rate': 0.099823, 'epoch': 1}
Step 3500: {'loss': 0.9401, 'grad_norm': 1.618773, 'learning_rate': 0.099821, 'epoch': 1}
Step 3550: {'loss': 0.9385, 'grad_norm': 5.025835, 'learning_rate': 0.099818, 'epoch': 1}
Step 3600: {'loss': 0.9302, 'grad_norm': 0.85456, 'learning_rate': 0.099816, 'epoch': 1}
Step 3650: {'loss': 0.8968, 'grad_norm': 1.834356, 'learning_rate': 0.099813, 'epoch': 1}
Step 3700: {'loss': 0.8975, 'grad_norm': 1.998562, 'learning_rate': 0.099811, 'epoch': 1}
Step 3750: {'loss': 0.896, 'grad_norm': 1.38505, 'learning_rate': 0.099808, 'epoch': 1}
Step 3800: {'loss': 0.8716, 'grad_norm': 2.471511, 'learning_rate': 0.099805, 'epoch': 1}
Step 3850: {'loss': 0.8831, 'grad_norm': 6.340622, 'learning_rate': 0.099803, 'epoch': 1}
Load dataset file 2024-01-18.feather from source
Load dataset sucessfully.
Step 3900: {'loss': 0.9761, 'grad_norm': 1.032292, 'learning_rate': 0.0998, 'epoch': 1}
Step 3950: {'loss': 1.0818, 'grad_norm': 9.918522, 'learning_rate': 0.099798, 'epoch': 1}
Step 4000: {'loss': 1.1397, 'grad_norm': 8.700916, 'learning_rate': 0.099795, 'epoch': 1}
Step 4050: {'loss': 1.1295, 'grad_norm': 5.110162, 'learning_rate': 0.099793, 'epoch': 1}
Step 4100: {'loss': 1.0623, 'grad_norm': 8.092234, 'learning_rate': 0.09979, 'epoch': 1}
Step 4150: {'loss': 1.0198, 'grad_norm': 3.991979, 'learning_rate': 0.099788, 'epoch': 1}
Step 4200: {'loss': 0.9998, 'grad_norm': 4.1145, 'learning_rate': 0.099785, 'epoch': 1}
Step 4250: {'loss': 0.9863, 'grad_norm': 0.864304, 'learning_rate': 0.099782, 'epoch': 1}
Step 4300: {'loss': 0.9354, 'grad_norm': 1.501979, 'learning_rate': 0.09978, 'epoch': 1}
Step 4350: {'loss': 0.9629, 'grad_norm': 4.901769, 'learning_rate': 0.099777, 'epoch': 1}
Step 4400: {'loss': 0.9367, 'grad_norm': 2.707478, 'learning_rate': 0.099775, 'epoch': 1}
Step 4450: {'loss': 0.9243, 'grad_norm': 2.15618, 'learning_rate': 0.099772, 'epoch': 1}
Step 4500: {'loss': 0.9228, 'grad_norm': 0.922842, 'learning_rate': 0.09977, 'epoch': 1}
Step 4550: {'loss': 0.9609, 'grad_norm': 5.06975, 'learning_rate': 0.099767, 'epoch': 1}
Step 4600: {'loss': 0.9221, 'grad_norm': 0.962733, 'learning_rate': 0.099764, 'epoch': 1}
Step 4650: {'loss': 0.892, 'grad_norm': 0.760606, 'learning_rate': 0.099762, 'epoch': 1}
Load dataset file 2024-01-19.feather from source
Load dataset sucessfully.
Step 4700: {'loss': 1.0322, 'grad_norm': 5.242667, 'learning_rate': 0.099759, 'epoch': 1}
Step 4750: {'loss': 1.051, 'grad_norm': 5.277212, 'learning_rate': 0.099757, 'epoch': 1}
Step 4800: {'loss': 1.0713, 'grad_norm': 1.531003, 'learning_rate': 0.099754, 'epoch': 1}
Step 4850: {'loss': 1.0481, 'grad_norm': 2.539943, 'learning_rate': 0.099752, 'epoch': 1}
Step 4900: {'loss': 1.0269, 'grad_norm': 3.988869, 'learning_rate': 0.099749, 'epoch': 1}
Step 4950: {'loss': 1.011, 'grad_norm': 8.213222, 'learning_rate': 0.099747, 'epoch': 1}
Step 5000: {'loss': 0.984, 'grad_norm': 2.532432, 'learning_rate': 0.099744, 'epoch': 1}
Step 5050: {'loss': 0.9881, 'grad_norm': 4.45067, 'learning_rate': 0.099741, 'epoch': 1}
Step 5100: {'loss': 0.954, 'grad_norm': 1.22309, 'learning_rate': 0.099739, 'epoch': 1}
Step 5150: {'loss': 0.9533, 'grad_norm': 1.460318, 'learning_rate': 0.099736, 'epoch': 1}
Step 5200: {'loss': 0.9422, 'grad_norm': 7.648223, 'learning_rate': 0.099734, 'epoch': 1}
Step 5250: {'loss': 0.9431, 'grad_norm': 4.580986, 'learning_rate': 0.099731, 'epoch': 1}
Step 5300: {'loss': 0.9237, 'grad_norm': 1.94742, 'learning_rate': 0.099729, 'epoch': 1}
Step 5350: {'loss': 0.9334, 'grad_norm': 3.123439, 'learning_rate': 0.099726, 'epoch': 1}
Step 5400: {'loss': 0.9144, 'grad_norm': 2.084524, 'learning_rate': 0.099724, 'epoch': 1}
Step 5450: {'loss': 0.9039, 'grad_norm': 6.727983, 'learning_rate': 0.099721, 'epoch': 1}
Load dataset file 2024-01-20.feather from source
Load dataset sucessfully.
Step 5500: {'loss': 1.0617, 'grad_norm': 2.11557, 'learning_rate': 0.099718, 'epoch': 1}
Step 5550: {'loss': 1.1061, 'grad_norm': 4.65687, 'learning_rate': 0.099716, 'epoch': 1}
Step 5600: {'loss': 1.0531, 'grad_norm': 1.92864, 'learning_rate': 0.099713, 'epoch': 1}
Step 5650: {'loss': 1.0412, 'grad_norm': 5.652185, 'learning_rate': 0.099711, 'epoch': 1}
Step 5700: {'loss': 1.0556, 'grad_norm': 6.693865, 'learning_rate': 0.099708, 'epoch': 1}
Step 5750: {'loss': 1.006, 'grad_norm': 3.715623, 'learning_rate': 0.099706, 'epoch': 1}
Step 5800: {'loss': 1.0178, 'grad_norm': 3.812249, 'learning_rate': 0.099703, 'epoch': 1}
Step 5850: {'loss': 1.0121, 'grad_norm': 3.401892, 'learning_rate': 0.0997, 'epoch': 1}
Step 5900: {'loss': 0.9777, 'grad_norm': 3.154646, 'learning_rate': 0.099698, 'epoch': 1}
Step 5950: {'loss': 0.9546, 'grad_norm': 1.385778, 'learning_rate': 0.099695, 'epoch': 1}
Step 6000: {'loss': 0.9704, 'grad_norm': 2.830461, 'learning_rate': 0.099693, 'epoch': 1}
Step 6050: {'loss': 0.9651, 'grad_norm': 4.789936, 'learning_rate': 0.09969, 'epoch': 1}
Step 6100: {'loss': 1.0155, 'grad_norm': 7.537683, 'learning_rate': 0.099688, 'epoch': 1}
Step 6150: {'loss': 0.962, 'grad_norm': 5.185128, 'learning_rate': 0.099685, 'epoch': 1}
Step 6200: {'loss': 0.9293, 'grad_norm': 1.817795, 'learning_rate': 0.099683, 'epoch': 1}
Step 6250: {'loss': 0.9392, 'grad_norm': 5.9968, 'learning_rate': 0.09968, 'epoch': 1}
Step 6300: {'loss': 0.9277, 'grad_norm': 0.847758, 'learning_rate': 0.099677, 'epoch': 1}
Load dataset file 2024-01-21.feather from source
Load dataset sucessfully.
Step 6350: {'loss': 0.964, 'grad_norm': 2.317808, 'learning_rate': 0.099675, 'epoch': 1}
Step 6400: {'loss': 1.1092, 'grad_norm': 1.844732, 'learning_rate': 0.099672, 'epoch': 1}
Step 6450: {'loss': 1.1098, 'grad_norm': 2.523263, 'learning_rate': 0.09967, 'epoch': 1}
Step 6500: {'loss': 1.0652, 'grad_norm': 4.097536, 'learning_rate': 0.099667, 'epoch': 1}
Step 6550: {'loss': 1.1118, 'grad_norm': 11.2714, 'learning_rate': 0.099665, 'epoch': 1}
Step 6600: {'loss': 1.15, 'grad_norm': 2.809983, 'learning_rate': 0.099662, 'epoch': 1}
Step 6650: {'loss': 1.0851, 'grad_norm': 1.999404, 'learning_rate': 0.09966, 'epoch': 1}
Step 6700: {'loss': 1.0336, 'grad_norm': 6.954432, 'learning_rate': 0.099657, 'epoch': 1}
Step 6750: {'loss': 1.0155, 'grad_norm': 4.871911, 'learning_rate': 0.099654, 'epoch': 1}
Step 6800: {'loss': 0.9877, 'grad_norm': 2.298141, 'learning_rate': 0.099652, 'epoch': 1}
Step 6850: {'loss': 1.0101, 'grad_norm': 1.50923, 'learning_rate': 0.099649, 'epoch': 1}
Step 6900: {'loss': 1.0377, 'grad_norm': 2.331067, 'learning_rate': 0.099647, 'epoch': 1}
Step 6950: {'loss': 0.9977, 'grad_norm': 6.538217, 'learning_rate': 0.099644, 'epoch': 1}
Step 7000: {'loss': 0.9796, 'grad_norm': 5.661006, 'learning_rate': 0.099642, 'epoch': 1}
Step 7050: {'loss': 0.9743, 'grad_norm': 0.848338, 'learning_rate': 0.099639, 'epoch': 1}
Step 7100: {'loss': 0.9664, 'grad_norm': 3.897578, 'learning_rate': 0.099636, 'epoch': 1}
Step 7150: {'loss': 0.9614, 'grad_norm': 10.31179, 'learning_rate': 0.099634, 'epoch': 1}
Load dataset file 2024-01-22.feather from source
Load dataset sucessfully.
Step 7200: {'loss': 1.0309, 'grad_norm': 3.126379, 'learning_rate': 0.099631, 'epoch': 1}
Step 7250: {'loss': 1.1978, 'grad_norm': 7.776375, 'learning_rate': 0.099629, 'epoch': 1}
Step 7300: {'loss': 1.2308, 'grad_norm': 7.1659, 'learning_rate': 0.099626, 'epoch': 1}
Step 7350: {'loss': 1.142, 'grad_norm': 0.751575, 'learning_rate': 0.099624, 'epoch': 1}
Step 7400: {'loss': 1.0581, 'grad_norm': 3.876262, 'learning_rate': 0.099621, 'epoch': 1}
Step 7450: {'loss': 1.1758, 'grad_norm': 9.960173, 'learning_rate': 0.099619, 'epoch': 1}
Step 7500: {'loss': 1.0831, 'grad_norm': 5.801623, 'learning_rate': 0.099616, 'epoch': 1}
Step 7550: {'loss': 1.0333, 'grad_norm': 1.16687, 'learning_rate': 0.099613, 'epoch': 1}
Step 7600: {'loss': 1.024, 'grad_norm': 2.305305, 'learning_rate': 0.099611, 'epoch': 1}
Step 7650: {'loss': 1.0026, 'grad_norm': 2.85073, 'learning_rate': 0.099608, 'epoch': 1}
Step 7700: {'loss': 1.0156, 'grad_norm': 3.20014, 'learning_rate': 0.099606, 'epoch': 1}
Step 7750: {'loss': 0.9738, 'grad_norm': 3.033872, 'learning_rate': 0.099603, 'epoch': 1}
Step 7800: {'loss': 0.9854, 'grad_norm': 1.248542, 'learning_rate': 0.099601, 'epoch': 1}
Step 7850: {'loss': 0.9774, 'grad_norm': 2.772385, 'learning_rate': 0.099598, 'epoch': 1}
Step 7900: {'loss': 0.9722, 'grad_norm': 0.713305, 'learning_rate': 0.099596, 'epoch': 1}
Step 7950: {'loss': 0.9694, 'grad_norm': 1.31272, 'learning_rate': 0.099593, 'epoch': 1}
Load dataset file 2024-01-23.feather from source
Load dataset sucessfully.
Step 8000: {'loss': 1.0731, 'grad_norm': 6.391376, 'learning_rate': 0.09959, 'epoch': 1}
Step 8050: {'loss': 1.1276, 'grad_norm': 6.396901, 'learning_rate': 0.099588, 'epoch': 1}
Step 8100: {'loss': 1.1159, 'grad_norm': 7.90421, 'learning_rate': 0.099585, 'epoch': 1}
Step 8150: {'loss': 1.0818, 'grad_norm': 4.570031, 'learning_rate': 0.099583, 'epoch': 1}
Step 8200: {'loss': 1.0736, 'grad_norm': 3.149643, 'learning_rate': 0.09958, 'epoch': 1}
Step 8250: {'loss': 1.0357, 'grad_norm': 2.956642, 'learning_rate': 0.099578, 'epoch': 1}
Step 8300: {'loss': 1.0306, 'grad_norm': 0.396999, 'learning_rate': 0.099575, 'epoch': 1}
Step 8350: {'loss': 1.0206, 'grad_norm': 3.09811, 'learning_rate': 0.099572, 'epoch': 1}
Step 8400: {'loss': 1.0146, 'grad_norm': 5.022635, 'learning_rate': 0.09957, 'epoch': 1}
Step 8450: {'loss': 1.0145, 'grad_norm': 5.459879, 'learning_rate': 0.099567, 'epoch': 1}
Step 8500: {'loss': 1.024, 'grad_norm': 4.021894, 'learning_rate': 0.099565, 'epoch': 1}
Step 8550: {'loss': 0.9857, 'grad_norm': 1.72161, 'learning_rate': 0.099562, 'epoch': 1}
Step 8600: {'loss': 1.0145, 'grad_norm': 1.662171, 'learning_rate': 0.09956, 'epoch': 1}
Step 8650: {'loss': 0.9867, 'grad_norm': 4.07841, 'learning_rate': 0.099557, 'epoch': 1}
2025-02-07 01:17:47.813 | INFO     | Nexus.training.embedder.recommendation.trainer:update_item_vectors:45 - Update item vectors...
2025-02-07 01:22:23.906 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:37 - Model saved in ./saves/ckpt/checkpoint-10000.
2025-02-07 01:22:24.729 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:40 - Item vectors saved to ./saves/ckpt/checkpoint-10000.
Step 8700: {'loss': 0.9738, 'grad_norm': 2.809635, 'learning_rate': 0.099555, 'epoch': 1}
Load dataset file 2024-01-24.feather from source
Load dataset sucessfully.
Step 8750: {'loss': 0.9619, 'grad_norm': 2.736058, 'learning_rate': 0.099552, 'epoch': 1}
Step 8800: {'loss': 1.1425, 'grad_norm': 5.275866, 'learning_rate': 0.099549, 'epoch': 1}
Step 8850: {'loss': 1.1598, 'grad_norm': 2.078836, 'learning_rate': 0.099547, 'epoch': 1}
Step 8900: {'loss': 1.0818, 'grad_norm': 3.665145, 'learning_rate': 0.099544, 'epoch': 1}
Step 8950: {'loss': 1.0785, 'grad_norm': 3.693236, 'learning_rate': 0.099542, 'epoch': 1}
Step 9000: {'loss': 1.0961, 'grad_norm': 21.519629, 'learning_rate': 0.099539, 'epoch': 1}
Step 9050: {'loss': 1.0677, 'grad_norm': 5.723701, 'learning_rate': 0.099537, 'epoch': 1}
Step 9100: {'loss': 1.0657, 'grad_norm': 6.810471, 'learning_rate': 0.099534, 'epoch': 1}
Step 9150: {'loss': 1.0532, 'grad_norm': 5.975116, 'learning_rate': 0.099532, 'epoch': 1}
Step 9200: {'loss': 1.0157, 'grad_norm': 3.246129, 'learning_rate': 0.099529, 'epoch': 1}
Step 9250: {'loss': 1.0279, 'grad_norm': 6.266159, 'learning_rate': 0.099526, 'epoch': 1}
Step 9300: {'loss': 1.011, 'grad_norm': 6.791999, 'learning_rate': 0.099524, 'epoch': 1}
Step 9350: {'loss': 1.015, 'grad_norm': 2.703289, 'learning_rate': 0.099521, 'epoch': 1}
Step 9400: {'loss': 0.9841, 'grad_norm': 4.035232, 'learning_rate': 0.099519, 'epoch': 1}
Step 9450: {'loss': 0.9915, 'grad_norm': 5.903772, 'learning_rate': 0.099516, 'epoch': 1}
Step 9500: {'loss': 0.9885, 'grad_norm': 5.10236, 'learning_rate': 0.099514, 'epoch': 1}
Step 9550: {'loss': 1.0348, 'grad_norm': 3.80653, 'learning_rate': 0.099511, 'epoch': 1}
Load dataset file 2024-01-25.feather from source
Load dataset sucessfully.
Step 9600: {'loss': 1.2571, 'grad_norm': 13.665407, 'learning_rate': 0.099508, 'epoch': 1}
Step 9650: {'loss': 1.1075, 'grad_norm': 4.800712, 'learning_rate': 0.099506, 'epoch': 1}
Step 9700: {'loss': 1.0987, 'grad_norm': 4.123148, 'learning_rate': 0.099503, 'epoch': 1}
Step 9750: {'loss': 1.0689, 'grad_norm': 2.157653, 'learning_rate': 0.099501, 'epoch': 1}
Step 9800: {'loss': 1.0545, 'grad_norm': 10.811826, 'learning_rate': 0.099498, 'epoch': 1}
Step 9850: {'loss': 1.0911, 'grad_norm': 5.473717, 'learning_rate': 0.099496, 'epoch': 1}
Step 9900: {'loss': 1.0438, 'grad_norm': 2.222537, 'learning_rate': 0.099493, 'epoch': 1}
Step 9950: {'loss': 1.0177, 'grad_norm': 4.549745, 'learning_rate': 0.099491, 'epoch': 1}
Step 10000: {'loss': 1.0263, 'grad_norm': 6.117959, 'learning_rate': 0.099488, 'epoch': 1}
Step 10050: {'loss': 1.0009, 'grad_norm': 1.514828, 'learning_rate': 0.099485, 'epoch': 1}
Step 10100: {'loss': 0.9888, 'grad_norm': 2.014053, 'learning_rate': 0.099483, 'epoch': 1}
Step 10150: {'loss': 1.0267, 'grad_norm': 8.514909, 'learning_rate': 0.09948, 'epoch': 1}
Step 10200: {'loss': 1.0521, 'grad_norm': 2.43622, 'learning_rate': 0.099478, 'epoch': 1}
Step 10250: {'loss': 0.9788, 'grad_norm': 1.269713, 'learning_rate': 0.099475, 'epoch': 1}
Step 10300: {'loss': 1.0164, 'grad_norm': 3.453384, 'learning_rate': 0.099473, 'epoch': 1}
Step 10350: {'loss': 1.0235, 'grad_norm': 3.170993, 'learning_rate': 0.09947, 'epoch': 1}
Load dataset file 2024-01-26.feather from source
Load dataset sucessfully.
Step 10400: {'loss': 1.0721, 'grad_norm': 4.400102, 'learning_rate': 0.099468, 'epoch': 1}
Step 10450: {'loss': 1.1203, 'grad_norm': 0.824897, 'learning_rate': 0.099465, 'epoch': 1}
Step 10500: {'loss': 1.1502, 'grad_norm': 5.851611, 'learning_rate': 0.099462, 'epoch': 1}
Step 10550: {'loss': 1.1223, 'grad_norm': 1.738795, 'learning_rate': 0.09946, 'epoch': 1}
Step 10600: {'loss': 1.1138, 'grad_norm': 6.76222, 'learning_rate': 0.099457, 'epoch': 1}
Step 10650: {'loss': 1.1602, 'grad_norm': 7.56995, 'learning_rate': 0.099455, 'epoch': 1}
Step 10700: {'loss': 1.0662, 'grad_norm': 4.683754, 'learning_rate': 0.099452, 'epoch': 1}
Step 10750: {'loss': 1.0622, 'grad_norm': 7.018296, 'learning_rate': 0.09945, 'epoch': 1}
Step 10800: {'loss': 1.0708, 'grad_norm': 5.573594, 'learning_rate': 0.099447, 'epoch': 1}
Step 10850: {'loss': 1.0572, 'grad_norm': 9.611142, 'learning_rate': 0.099444, 'epoch': 1}
Step 10900: {'loss': 1.0774, 'grad_norm': 4.99109, 'learning_rate': 0.099442, 'epoch': 1}
Step 10950: {'loss': 1.0037, 'grad_norm': 2.687713, 'learning_rate': 0.099439, 'epoch': 1}
Step 11000: {'loss': 1.0137, 'grad_norm': 1.623582, 'learning_rate': 0.099437, 'epoch': 1}
Step 11050: {'loss': 1.0348, 'grad_norm': 11.694195, 'learning_rate': 0.099434, 'epoch': 1}
Step 11100: {'loss': 1.0001, 'grad_norm': 4.910408, 'learning_rate': 0.099432, 'epoch': 1}
Step 11150: {'loss': 0.978, 'grad_norm': 3.231757, 'learning_rate': 0.099429, 'epoch': 1}
Step 11200: {'loss': 0.9869, 'grad_norm': 6.61661, 'learning_rate': 0.099427, 'epoch': 1}
Load dataset file 2024-01-27.feather from source
Load dataset sucessfully.
Step 11250: {'loss': 1.1287, 'grad_norm': 12.639695, 'learning_rate': 0.099424, 'epoch': 1}
Step 11300: {'loss': 1.1623, 'grad_norm': 3.967936, 'learning_rate': 0.099421, 'epoch': 1}
Step 11350: {'loss': 1.0988, 'grad_norm': 4.943474, 'learning_rate': 0.099419, 'epoch': 1}
Step 11400: {'loss': 1.1076, 'grad_norm': 4.835533, 'learning_rate': 0.099416, 'epoch': 1}
Step 11450: {'loss': 1.0733, 'grad_norm': 2.253525, 'learning_rate': 0.099414, 'epoch': 1}
Step 11500: {'loss': 1.0681, 'grad_norm': 2.033158, 'learning_rate': 0.099411, 'epoch': 1}
Step 11550: {'loss': 1.092, 'grad_norm': 3.547588, 'learning_rate': 0.099409, 'epoch': 1}
Step 11600: {'loss': 1.0859, 'grad_norm': 10.469138, 'learning_rate': 0.099406, 'epoch': 1}
Step 11650: {'loss': 1.0717, 'grad_norm': 4.847119, 'learning_rate': 0.099404, 'epoch': 1}
Step 11700: {'loss': 1.067, 'grad_norm': 5.625673, 'learning_rate': 0.099401, 'epoch': 1}
Step 11750: {'loss': 1.0474, 'grad_norm': 10.372197, 'learning_rate': 0.099398, 'epoch': 1}
Step 11800: {'loss': 1.0556, 'grad_norm': 4.802138, 'learning_rate': 0.099396, 'epoch': 1}
Step 11850: {'loss': 0.9971, 'grad_norm': 6.742066, 'learning_rate': 0.099393, 'epoch': 1}
Step 11900: {'loss': 1.0147, 'grad_norm': 7.038589, 'learning_rate': 0.099391, 'epoch': 1}
Step 11950: {'loss': 1.1175, 'grad_norm': 6.397113, 'learning_rate': 0.099388, 'epoch': 1}
Step 12000: {'loss': 1.008, 'grad_norm': 3.48753, 'learning_rate': 0.099386, 'epoch': 1}
Step 12050: {'loss': 1.0416, 'grad_norm': 5.538133, 'learning_rate': 0.099383, 'epoch': 1}
Load dataset file 2024-01-28.feather from source
Load dataset sucessfully.
Step 12100: {'loss': 1.0887, 'grad_norm': 6.943871, 'learning_rate': 0.09938, 'epoch': 1}
Step 12150: {'loss': 1.143, 'grad_norm': 6.137291, 'learning_rate': 0.099378, 'epoch': 1}
Step 12200: {'loss': 1.1407, 'grad_norm': 8.709136, 'learning_rate': 0.099375, 'epoch': 1}
Step 12250: {'loss': 1.1456, 'grad_norm': 12.43532, 'learning_rate': 0.099373, 'epoch': 1}
Step 12300: {'loss': 1.1391, 'grad_norm': 8.329797, 'learning_rate': 0.09937, 'epoch': 1}
Step 12350: {'loss': 1.1356, 'grad_norm': 7.783101, 'learning_rate': 0.099368, 'epoch': 1}
Step 12400: {'loss': 1.1263, 'grad_norm': 13.423974, 'learning_rate': 0.099365, 'epoch': 1}
Step 12450: {'loss': 1.0789, 'grad_norm': 4.094548, 'learning_rate': 0.099363, 'epoch': 1}
Step 12500: {'loss': 1.0917, 'grad_norm': 7.11959, 'learning_rate': 0.09936, 'epoch': 1}
Step 12550: {'loss': 1.0804, 'grad_norm': 0.979854, 'learning_rate': 0.099357, 'epoch': 1}
Step 12600: {'loss': 1.0402, 'grad_norm': 4.25854, 'learning_rate': 0.099355, 'epoch': 1}
Step 12650: {'loss': 1.0405, 'grad_norm': 2.682053, 'learning_rate': 0.099352, 'epoch': 1}
Step 12700: {'loss': 1.0534, 'grad_norm': 5.706197, 'learning_rate': 0.09935, 'epoch': 1}
Step 12750: {'loss': 1.0219, 'grad_norm': 3.691821, 'learning_rate': 0.099347, 'epoch': 1}
Step 12800: {'loss': 1.0027, 'grad_norm': 3.582873, 'learning_rate': 0.099345, 'epoch': 1}
Step 12850: {'loss': 1.0155, 'grad_norm': 4.047683, 'learning_rate': 0.099342, 'epoch': 1}
Step 12900: {'loss': 1.0098, 'grad_norm': 8.561706, 'learning_rate': 0.09934, 'epoch': 1}
Load dataset file 2024-01-29.feather from source
Load dataset sucessfully.
Step 12950: {'loss': 1.1375, 'grad_norm': 6.929187, 'learning_rate': 0.099337, 'epoch': 1}
Step 13000: {'loss': 1.1594, 'grad_norm': 1.852059, 'learning_rate': 0.099334, 'epoch': 1}
Step 13050: {'loss': 1.1194, 'grad_norm': 2.282602, 'learning_rate': 0.099332, 'epoch': 1}
Step 13100: {'loss': 1.1112, 'grad_norm': 4.882621, 'learning_rate': 0.099329, 'epoch': 1}
Step 13150: {'loss': 1.099, 'grad_norm': 4.786894, 'learning_rate': 0.099327, 'epoch': 1}
Step 13200: {'loss': 1.0955, 'grad_norm': 15.116144, 'learning_rate': 0.099324, 'epoch': 1}
Step 13250: {'loss': 1.1103, 'grad_norm': 6.842777, 'learning_rate': 0.099322, 'epoch': 1}
Step 13300: {'loss': 1.0809, 'grad_norm': 2.158784, 'learning_rate': 0.099319, 'epoch': 1}
Step 13350: {'loss': 1.0908, 'grad_norm': 9.123536, 'learning_rate': 0.099316, 'epoch': 1}
Step 13400: {'loss': 1.0688, 'grad_norm': 2.210542, 'learning_rate': 0.099314, 'epoch': 1}
Step 13450: {'loss': 1.0171, 'grad_norm': 4.04225, 'learning_rate': 0.099311, 'epoch': 1}
Step 13500: {'loss': 1.0112, 'grad_norm': 7.572313, 'learning_rate': 0.099309, 'epoch': 1}
Step 13550: {'loss': 1.0452, 'grad_norm': 1.988288, 'learning_rate': 0.099306, 'epoch': 1}
Step 13600: {'loss': 1.0263, 'grad_norm': 4.454008, 'learning_rate': 0.099304, 'epoch': 1}
Step 13650: {'loss': 0.9824, 'grad_norm': 5.82394, 'learning_rate': 0.099301, 'epoch': 1}
Step 13700: {'loss': 1.0179, 'grad_norm': 5.382858, 'learning_rate': 0.099299, 'epoch': 1}
Load dataset file 2024-01-30.feather from source
Load dataset sucessfully.
Step 13750: {'loss': 1.1421, 'grad_norm': 7.48446, 'learning_rate': 0.099296, 'epoch': 1}
Step 13800: {'loss': 1.1775, 'grad_norm': 12.854665, 'learning_rate': 0.099293, 'epoch': 1}
Step 13850: {'loss': 1.1554, 'grad_norm': 8.283678, 'learning_rate': 0.099291, 'epoch': 1}
Step 13900: {'loss': 1.1526, 'grad_norm': 4.603949, 'learning_rate': 0.099288, 'epoch': 1}
Step 13950: {'loss': 1.1294, 'grad_norm': 13.142829, 'learning_rate': 0.099286, 'epoch': 1}
Step 14000: {'loss': 1.1241, 'grad_norm': 5.452623, 'learning_rate': 0.099283, 'epoch': 1}
Step 14050: {'loss': 1.1238, 'grad_norm': 5.222189, 'learning_rate': 0.099281, 'epoch': 1}
Step 14100: {'loss': 1.1049, 'grad_norm': 12.776435, 'learning_rate': 0.099278, 'epoch': 1}
Step 14150: {'loss': 1.0921, 'grad_norm': 5.098847, 'learning_rate': 0.099276, 'epoch': 1}
Step 14200: {'loss': 1.1005, 'grad_norm': 4.708395, 'learning_rate': 0.099273, 'epoch': 1}
Step 14250: {'loss': 1.0787, 'grad_norm': 13.000138, 'learning_rate': 0.09927, 'epoch': 1}
Step 14300: {'loss': 1.0714, 'grad_norm': 6.66676, 'learning_rate': 0.099268, 'epoch': 1}
Step 14350: {'loss': 1.0703, 'grad_norm': 6.896259, 'learning_rate': 0.099265, 'epoch': 1}
Step 14400: {'loss': 1.0589, 'grad_norm': 13.057234, 'learning_rate': 0.099263, 'epoch': 1}
Step 14450: {'loss': 1.044, 'grad_norm': 6.567488, 'learning_rate': 0.09926, 'epoch': 1}
Load dataset file 2024-01-31.feather from source
Load dataset sucessfully.
Step 14500: {'loss': 1.167, 'grad_norm': 6.522788, 'learning_rate': 0.099258, 'epoch': 1}
Step 14550: {'loss': 1.1269, 'grad_norm': 1.288531, 'learning_rate': 0.099255, 'epoch': 1}
Step 14600: {'loss': 1.1027, 'grad_norm': 4.086196, 'learning_rate': 0.099252, 'epoch': 1}
Step 14650: {'loss': 1.1209, 'grad_norm': 7.310288, 'learning_rate': 0.09925, 'epoch': 1}
Step 14700: {'loss': 1.1461, 'grad_norm': 6.548299, 'learning_rate': 0.099247, 'epoch': 1}
Step 14750: {'loss': 1.1307, 'grad_norm': 3.49495, 'learning_rate': 0.099245, 'epoch': 1}
Step 14800: {'loss': 1.0648, 'grad_norm': 2.087119, 'learning_rate': 0.099242, 'epoch': 1}
Step 14850: {'loss': 1.0554, 'grad_norm': 2.516897, 'learning_rate': 0.09924, 'epoch': 1}
Step 14900: {'loss': 1.0434, 'grad_norm': 1.680933, 'learning_rate': 0.099237, 'epoch': 1}
Step 14950: {'loss': 1.08, 'grad_norm': 3.62768, 'learning_rate': 0.099235, 'epoch': 1}
Step 15000: {'loss': 1.0754, 'grad_norm': 16.972355, 'learning_rate': 0.099232, 'epoch': 1}
Step 15050: {'loss': 1.0597, 'grad_norm': 8.038582, 'learning_rate': 0.099229, 'epoch': 1}
Step 15100: {'loss': 1.0625, 'grad_norm': 4.20408, 'learning_rate': 0.099227, 'epoch': 1}
Step 15150: {'loss': 1.0467, 'grad_norm': 8.40633, 'learning_rate': 0.099224, 'epoch': 1}
Step 15200: {'loss': 1.0422, 'grad_norm': 8.686363, 'learning_rate': 0.099222, 'epoch': 1}
Load dataset file 2024-02-01.feather from source
Load dataset sucessfully.
Step 15250: {'loss': 1.0952, 'grad_norm': 5.278051, 'learning_rate': 0.099219, 'epoch': 1}
Step 15300: {'loss': 1.1626, 'grad_norm': 5.230448, 'learning_rate': 0.099217, 'epoch': 1}
Step 15350: {'loss': 1.1455, 'grad_norm': 7.681131, 'learning_rate': 0.099214, 'epoch': 1}
Step 15400: {'loss': 1.1279, 'grad_norm': 7.414609, 'learning_rate': 0.099212, 'epoch': 1}
Step 15450: {'loss': 1.1074, 'grad_norm': 5.722234, 'learning_rate': 0.099209, 'epoch': 1}
Step 15500: {'loss': 1.1034, 'grad_norm': 5.85613, 'learning_rate': 0.099206, 'epoch': 1}
Step 15550: {'loss': 1.0759, 'grad_norm': 6.244353, 'learning_rate': 0.099204, 'epoch': 1}
Step 15600: {'loss': 1.0383, 'grad_norm': 7.437213, 'learning_rate': 0.099201, 'epoch': 1}
Step 15650: {'loss': 1.0846, 'grad_norm': 4.319961, 'learning_rate': 0.099199, 'epoch': 1}
Step 15700: {'loss': 0.997, 'grad_norm': 2.360207, 'learning_rate': 0.099196, 'epoch': 1}
Step 15750: {'loss': 0.9801, 'grad_norm': 3.089299, 'learning_rate': 0.099194, 'epoch': 1}
Step 15800: {'loss': 0.9847, 'grad_norm': 5.907218, 'learning_rate': 0.099191, 'epoch': 1}
Step 15850: {'loss': 0.984, 'grad_norm': 4.750807, 'learning_rate': 0.099188, 'epoch': 1}
Step 15900: {'loss': 0.9816, 'grad_norm': 5.062254, 'learning_rate': 0.099186, 'epoch': 1}
Step 15950: {'loss': 0.9926, 'grad_norm': 10.221534, 'learning_rate': 0.099183, 'epoch': 1}
Load dataset file 2024-02-02.feather from source
Load dataset sucessfully.
Step 16000: {'loss': 1.021, 'grad_norm': 8.016011, 'learning_rate': 0.099181, 'epoch': 1}
Step 16050: {'loss': 1.1556, 'grad_norm': 6.552951, 'learning_rate': 0.099178, 'epoch': 1}
Step 16100: {'loss': 1.1333, 'grad_norm': 6.713649, 'learning_rate': 0.099176, 'epoch': 1}
Step 16150: {'loss': 1.0967, 'grad_norm': 9.033187, 'learning_rate': 0.099173, 'epoch': 1}
Step 16200: {'loss': 1.115, 'grad_norm': 7.222685, 'learning_rate': 0.099171, 'epoch': 1}
Step 16250: {'loss': 1.0957, 'grad_norm': 9.225799, 'learning_rate': 0.099168, 'epoch': 1}
Step 16300: {'loss': 1.0803, 'grad_norm': 4.493891, 'learning_rate': 0.099165, 'epoch': 1}
Step 16350: {'loss': 1.0825, 'grad_norm': 18.20599, 'learning_rate': 0.099163, 'epoch': 1}
Step 16400: {'loss': 1.0581, 'grad_norm': 8.148104, 'learning_rate': 0.09916, 'epoch': 1}
Step 16450: {'loss': 1.0436, 'grad_norm': 8.186865, 'learning_rate': 0.099158, 'epoch': 1}
Step 16500: {'loss': 1.0467, 'grad_norm': 4.469238, 'learning_rate': 0.099155, 'epoch': 1}
Step 16550: {'loss': 1.0315, 'grad_norm': 9.341187, 'learning_rate': 0.099153, 'epoch': 1}
Step 16600: {'loss': 0.979, 'grad_norm': 5.656954, 'learning_rate': 0.09915, 'epoch': 1}
Step 16650: {'loss': 0.9649, 'grad_norm': 6.936502, 'learning_rate': 0.099148, 'epoch': 1}
Step 16700: {'loss': 1.0171, 'grad_norm': 3.169098, 'learning_rate': 0.099145, 'epoch': 1}
Load dataset file 2024-02-03.feather from source
Load dataset sucessfully.
Step 16750: {'loss': 1.1121, 'grad_norm': 2.935831, 'learning_rate': 0.099142, 'epoch': 1}
Step 16800: {'loss': 1.1372, 'grad_norm': 8.554106, 'learning_rate': 0.09914, 'epoch': 1}
Step 16850: {'loss': 1.1019, 'grad_norm': 4.478212, 'learning_rate': 0.099137, 'epoch': 1}
Step 16900: {'loss': 1.0999, 'grad_norm': 11.233074, 'learning_rate': 0.099135, 'epoch': 1}
Step 16950: {'loss': 1.1206, 'grad_norm': 8.244231, 'learning_rate': 0.099132, 'epoch': 1}
Step 17000: {'loss': 1.1111, 'grad_norm': 2.178182, 'learning_rate': 0.09913, 'epoch': 1}
Step 17050: {'loss': 1.0735, 'grad_norm': 5.534226, 'learning_rate': 0.099127, 'epoch': 1}
Step 17100: {'loss': 1.0394, 'grad_norm': 5.719088, 'learning_rate': 0.099124, 'epoch': 1}
Step 17150: {'loss': 1.0613, 'grad_norm': 1.60876, 'learning_rate': 0.099122, 'epoch': 1}
Step 17200: {'loss': 1.0731, 'grad_norm': 10.661415, 'learning_rate': 0.099119, 'epoch': 1}
2025-02-07 02:45:15.026 | INFO     | Nexus.training.embedder.recommendation.trainer:update_item_vectors:45 - Update item vectors...
2025-02-07 02:49:50.526 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:37 - Model saved in ./saves/ckpt/checkpoint-20000.
2025-02-07 02:49:51.343 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:40 - Item vectors saved to ./saves/ckpt/checkpoint-20000.
Step 17250: {'loss': 1.0581, 'grad_norm': 6.569238, 'learning_rate': 0.099117, 'epoch': 1}
Step 17300: {'loss': 1.0563, 'grad_norm': 2.362698, 'learning_rate': 0.099114, 'epoch': 1}
Step 17350: {'loss': 1.0115, 'grad_norm': 8.2256, 'learning_rate': 0.099112, 'epoch': 1}
Step 17400: {'loss': 1.0443, 'grad_norm': 6.201876, 'learning_rate': 0.099109, 'epoch': 1}
Step 17450: {'loss': 1.0258, 'grad_norm': 4.483819, 'learning_rate': 0.099107, 'epoch': 1}
Load dataset file 2024-02-04.feather from source
Load dataset sucessfully.
Step 17500: {'loss': 1.062, 'grad_norm': 9.403328, 'learning_rate': 0.099104, 'epoch': 1}
Step 17550: {'loss': 1.1629, 'grad_norm': 13.594753, 'learning_rate': 0.099101, 'epoch': 1}
Step 17600: {'loss': 1.1393, 'grad_norm': 4.78133, 'learning_rate': 0.099099, 'epoch': 1}
Step 17650: {'loss': 1.1113, 'grad_norm': 9.800066, 'learning_rate': 0.099096, 'epoch': 1}
Step 17700: {'loss': 1.131, 'grad_norm': 1.997259, 'learning_rate': 0.099094, 'epoch': 1}
Step 17750: {'loss': 1.1366, 'grad_norm': 14.664123, 'learning_rate': 0.099091, 'epoch': 1}
Step 17800: {'loss': 1.1059, 'grad_norm': 6.196086, 'learning_rate': 0.099089, 'epoch': 1}
Step 17850: {'loss': 1.0747, 'grad_norm': 1.960924, 'learning_rate': 0.099086, 'epoch': 1}
Step 17900: {'loss': 1.0263, 'grad_norm': 3.797501, 'learning_rate': 0.099084, 'epoch': 1}
Step 17950: {'loss': 1.0283, 'grad_norm': 1.275773, 'learning_rate': 0.099081, 'epoch': 1}
Step 18000: {'loss': 1.0025, 'grad_norm': 11.543327, 'learning_rate': 0.099078, 'epoch': 1}
Step 18050: {'loss': 1.0327, 'grad_norm': 8.684623, 'learning_rate': 0.099076, 'epoch': 1}
Step 18100: {'loss': 1.0695, 'grad_norm': 13.131787, 'learning_rate': 0.099073, 'epoch': 1}
Step 18150: {'loss': 1.0207, 'grad_norm': 4.977026, 'learning_rate': 0.099071, 'epoch': 1}
Step 18200: {'loss': 1.0203, 'grad_norm': 5.974127, 'learning_rate': 0.099068, 'epoch': 1}
Load dataset file 2024-02-05.feather from source
Load dataset sucessfully.
Step 18250: {'loss': 0.975, 'grad_norm': 3.454222, 'learning_rate': 0.099066, 'epoch': 1}
Step 18300: {'loss': 1.1592, 'grad_norm': 2.591521, 'learning_rate': 0.099063, 'epoch': 1}
Step 18350: {'loss': 1.1034, 'grad_norm': 5.040372, 'learning_rate': 0.09906, 'epoch': 1}
Step 18400: {'loss': 1.1745, 'grad_norm': 4.74827, 'learning_rate': 0.099058, 'epoch': 1}
Step 18450: {'loss': 1.1024, 'grad_norm': 5.34392, 'learning_rate': 0.099055, 'epoch': 1}
Step 18500: {'loss': 1.1001, 'grad_norm': 10.445362, 'learning_rate': 0.099053, 'epoch': 1}
Step 18550: {'loss': 1.0884, 'grad_norm': 4.391602, 'learning_rate': 0.09905, 'epoch': 1}
Step 18600: {'loss': 1.0567, 'grad_norm': 13.710696, 'learning_rate': 0.099048, 'epoch': 1}
Step 18650: {'loss': 1.0622, 'grad_norm': 5.847498, 'learning_rate': 0.099045, 'epoch': 1}
Step 18700: {'loss': 1.0488, 'grad_norm': 2.740081, 'learning_rate': 0.099043, 'epoch': 1}
Step 18750: {'loss': 1.0531, 'grad_norm': 9.388561, 'learning_rate': 0.09904, 'epoch': 1}
Step 18800: {'loss': 1.0524, 'grad_norm': 3.784644, 'learning_rate': 0.099037, 'epoch': 1}
Step 18850: {'loss': 1.0255, 'grad_norm': 6.806295, 'learning_rate': 0.099035, 'epoch': 1}
Step 18900: {'loss': 1.0226, 'grad_norm': 4.598954, 'learning_rate': 0.099032, 'epoch': 1}
Load dataset file 2024-02-06.feather from source
Load dataset sucessfully.
Step 18950: {'loss': 1.0791, 'grad_norm': 2.777993, 'learning_rate': 0.09903, 'epoch': 1}
Step 19000: {'loss': 1.1082, 'grad_norm': 4.376669, 'learning_rate': 0.099027, 'epoch': 1}
Step 19050: {'loss': 1.0931, 'grad_norm': 5.823201, 'learning_rate': 0.099025, 'epoch': 1}
Step 19100: {'loss': 1.0742, 'grad_norm': 3.126131, 'learning_rate': 0.099022, 'epoch': 1}
Step 19150: {'loss': 1.0589, 'grad_norm': 10.394468, 'learning_rate': 0.09902, 'epoch': 1}
Step 19200: {'loss': 1.0483, 'grad_norm': 6.269423, 'learning_rate': 0.099017, 'epoch': 1}
Step 19250: {'loss': 1.0665, 'grad_norm': 6.901346, 'learning_rate': 0.099014, 'epoch': 1}
Step 19300: {'loss': 1.0354, 'grad_norm': 1.822495, 'learning_rate': 0.099012, 'epoch': 1}
Step 19350: {'loss': 1.0573, 'grad_norm': 9.813018, 'learning_rate': 0.099009, 'epoch': 1}
Step 19400: {'loss': 1.0258, 'grad_norm': 3.1251, 'learning_rate': 0.099007, 'epoch': 1}
Step 19450: {'loss': 1.0319, 'grad_norm': 7.637957, 'learning_rate': 0.099004, 'epoch': 1}
Step 19500: {'loss': 1.0461, 'grad_norm': 1.934327, 'learning_rate': 0.099002, 'epoch': 1}
Step 19550: {'loss': 1.0377, 'grad_norm': 5.639593, 'learning_rate': 0.098999, 'epoch': 1}
Step 19600: {'loss': 1.0179, 'grad_norm': 4.02926, 'learning_rate': 0.098996, 'epoch': 1}
Load dataset file 2024-02-07.feather from source
Load dataset sucessfully.
Step 19650: {'loss': 1.0939, 'grad_norm': 7.394595, 'learning_rate': 0.098994, 'epoch': 1}
Step 19700: {'loss': 1.0838, 'grad_norm': 10.040878, 'learning_rate': 0.098991, 'epoch': 1}
Step 19750: {'loss': 1.1235, 'grad_norm': 12.47568, 'learning_rate': 0.098989, 'epoch': 1}
Step 19800: {'loss': 1.0874, 'grad_norm': 5.672122, 'learning_rate': 0.098986, 'epoch': 1}
Step 19850: {'loss': 1.0707, 'grad_norm': 5.662342, 'learning_rate': 0.098984, 'epoch': 1}
Step 19900: {'loss': 1.0323, 'grad_norm': 3.246499, 'learning_rate': 0.098981, 'epoch': 1}
Step 19950: {'loss': 1.0355, 'grad_norm': 4.066752, 'learning_rate': 0.098979, 'epoch': 1}
Step 20000: {'loss': 1.0315, 'grad_norm': 4.87769, 'learning_rate': 0.098976, 'epoch': 1}
Step 20050: {'loss': 0.9994, 'grad_norm': 3.928813, 'learning_rate': 0.098973, 'epoch': 1}
Step 20100: {'loss': 1.0089, 'grad_norm': 9.600618, 'learning_rate': 0.098971, 'epoch': 1}
Step 20150: {'loss': 1.0302, 'grad_norm': 6.978963, 'learning_rate': 0.098968, 'epoch': 1}
Step 20200: {'loss': 1.0146, 'grad_norm': 10.088704, 'learning_rate': 0.098966, 'epoch': 1}
Step 20250: {'loss': 1.0076, 'grad_norm': 5.328814, 'learning_rate': 0.098963, 'epoch': 1}
Step 20300: {'loss': 1.0045, 'grad_norm': 4.868725, 'learning_rate': 0.098961, 'epoch': 1}
Step 20350: {'loss': 0.9912, 'grad_norm': 5.590706, 'learning_rate': 0.098958, 'epoch': 1}
Load dataset file 2024-02-08.feather from source
Load dataset sucessfully.
Step 20400: {'loss': 1.161, 'grad_norm': 4.153763, 'learning_rate': 0.098956, 'epoch': 1}
Step 20450: {'loss': 1.0939, 'grad_norm': 4.380881, 'learning_rate': 0.098953, 'epoch': 1}
Step 20500: {'loss': 1.0753, 'grad_norm': 2.647929, 'learning_rate': 0.09895, 'epoch': 1}
Step 20550: {'loss': 1.0958, 'grad_norm': 9.247704, 'learning_rate': 0.098948, 'epoch': 1}
Step 20600: {'loss': 1.1327, 'grad_norm': 6.946059, 'learning_rate': 0.098945, 'epoch': 1}
Step 20650: {'loss': 1.0658, 'grad_norm': 8.521374, 'learning_rate': 0.098943, 'epoch': 1}
Step 20700: {'loss': 1.0545, 'grad_norm': 7.568822, 'learning_rate': 0.09894, 'epoch': 1}
Step 20750: {'loss': 1.0476, 'grad_norm': 9.495673, 'learning_rate': 0.098938, 'epoch': 1}
Step 20800: {'loss': 0.9904, 'grad_norm': 5.630363, 'learning_rate': 0.098935, 'epoch': 1}
Step 20850: {'loss': 1.0167, 'grad_norm': 12.239796, 'learning_rate': 0.098932, 'epoch': 1}
Step 20900: {'loss': 1.0376, 'grad_norm': 4.522248, 'learning_rate': 0.09893, 'epoch': 1}
Step 20950: {'loss': 1.0225, 'grad_norm': 6.982609, 'learning_rate': 0.098927, 'epoch': 1}
Step 21000: {'loss': 1.0115, 'grad_norm': 9.972112, 'learning_rate': 0.098925, 'epoch': 1}
Step 21050: {'loss': 1.0025, 'grad_norm': 7.134302, 'learning_rate': 0.098922, 'epoch': 1}
Load dataset file 2024-02-09.feather from source
Load dataset sucessfully.
Step 21100: {'loss': 1.0324, 'grad_norm': 1.732059, 'learning_rate': 0.09892, 'epoch': 1}
Step 21150: {'loss': 1.1428, 'grad_norm': 5.867017, 'learning_rate': 0.098917, 'epoch': 1}
Step 21200: {'loss': 1.0911, 'grad_norm': 12.381598, 'learning_rate': 0.098915, 'epoch': 1}
Step 21250: {'loss': 1.0756, 'grad_norm': 5.506622, 'learning_rate': 0.098912, 'epoch': 1}
Step 21300: {'loss': 1.0514, 'grad_norm': 3.176283, 'learning_rate': 0.098909, 'epoch': 1}
Step 21350: {'loss': 1.0391, 'grad_norm': 6.098115, 'learning_rate': 0.098907, 'epoch': 1}
Step 21400: {'loss': 1.0226, 'grad_norm': 5.287181, 'learning_rate': 0.098904, 'epoch': 1}
Step 21450: {'loss': 1.027, 'grad_norm': 2.736193, 'learning_rate': 0.098902, 'epoch': 1}
Step 21500: {'loss': 1.0244, 'grad_norm': 7.316805, 'learning_rate': 0.098899, 'epoch': 1}
Step 21550: {'loss': 1.0233, 'grad_norm': 1.872807, 'learning_rate': 0.098897, 'epoch': 1}
Step 21600: {'loss': 0.9747, 'grad_norm': 6.508302, 'learning_rate': 0.098894, 'epoch': 1}
Step 21650: {'loss': 0.9649, 'grad_norm': 4.649683, 'learning_rate': 0.098892, 'epoch': 1}
Step 21700: {'loss': 1.0239, 'grad_norm': 4.708187, 'learning_rate': 0.098889, 'epoch': 1}
Load dataset file 2024-02-10.feather from source
Load dataset sucessfully.
Step 21750: {'loss': 1.0237, 'grad_norm': 4.387501, 'learning_rate': 0.098886, 'epoch': 1}
Step 21800: {'loss': 1.1288, 'grad_norm': 14.278013, 'learning_rate': 0.098884, 'epoch': 1}
Step 21850: {'loss': 1.0772, 'grad_norm': 4.766689, 'learning_rate': 0.098881, 'epoch': 1}
Step 21900: {'loss': 1.0539, 'grad_norm': 11.653478, 'learning_rate': 0.098879, 'epoch': 1}
Step 21950: {'loss': 1.0462, 'grad_norm': 4.310433, 'learning_rate': 0.098876, 'epoch': 1}
Step 22000: {'loss': 1.0592, 'grad_norm': 4.128976, 'learning_rate': 0.098874, 'epoch': 1}
Step 22050: {'loss': 1.0247, 'grad_norm': 1.039127, 'learning_rate': 0.098871, 'epoch': 1}
Step 22100: {'loss': 1.0024, 'grad_norm': 6.917623, 'learning_rate': 0.098868, 'epoch': 1}
Step 22150: {'loss': 1.0259, 'grad_norm': 2.790083, 'learning_rate': 0.098866, 'epoch': 1}
Step 22200: {'loss': 1.0186, 'grad_norm': 4.725047, 'learning_rate': 0.098863, 'epoch': 1}
Step 22250: {'loss': 0.9738, 'grad_norm': 2.783575, 'learning_rate': 0.098861, 'epoch': 1}
Step 22300: {'loss': 0.968, 'grad_norm': 5.24055, 'learning_rate': 0.098858, 'epoch': 1}
Step 22350: {'loss': 0.9768, 'grad_norm': 10.363002, 'learning_rate': 0.098856, 'epoch': 1}
Step 22400: {'loss': 1.0618, 'grad_norm': 5.144931, 'learning_rate': 0.098853, 'epoch': 1}
Load dataset file 2024-02-11.feather from source
Load dataset sucessfully.
Step 22450: {'loss': 1.0022, 'grad_norm': 9.948432, 'learning_rate': 0.098851, 'epoch': 1}
Step 22500: {'loss': 1.123, 'grad_norm': 7.949596, 'learning_rate': 0.098848, 'epoch': 1}
Step 22550: {'loss': 1.1011, 'grad_norm': 6.185127, 'learning_rate': 0.098845, 'epoch': 1}
Step 22600: {'loss': 1.0704, 'grad_norm': 5.939396, 'learning_rate': 0.098843, 'epoch': 1}
Step 22650: {'loss': 1.0742, 'grad_norm': 4.600001, 'learning_rate': 0.09884, 'epoch': 1}
Step 22700: {'loss': 1.0749, 'grad_norm': 18.246687, 'learning_rate': 0.098838, 'epoch': 1}
Step 22750: {'loss': 1.0993, 'grad_norm': 1.939269, 'learning_rate': 0.098835, 'epoch': 1}
Step 22800: {'loss': 1.0227, 'grad_norm': 7.568744, 'learning_rate': 0.098833, 'epoch': 1}
Step 22850: {'loss': 1.0308, 'grad_norm': 7.633437, 'learning_rate': 0.09883, 'epoch': 1}
Step 22900: {'loss': 1.0054, 'grad_norm': 2.452587, 'learning_rate': 0.098828, 'epoch': 1}
Step 22950: {'loss': 1.0148, 'grad_norm': 14.978444, 'learning_rate': 0.098825, 'epoch': 1}
Step 23000: {'loss': 0.9944, 'grad_norm': 6.473099, 'learning_rate': 0.098822, 'epoch': 1}
Step 23050: {'loss': 0.9925, 'grad_norm': 15.282337, 'learning_rate': 0.09882, 'epoch': 1}
Step 23100: {'loss': 0.9802, 'grad_norm': 7.517778, 'learning_rate': 0.098817, 'epoch': 1}
Load dataset file 2024-02-12.feather from source
Load dataset sucessfully.
Step 23150: {'loss': 0.9872, 'grad_norm': 2.812132, 'learning_rate': 0.098815, 'epoch': 1}
Step 23200: {'loss': 1.1316, 'grad_norm': 11.542143, 'learning_rate': 0.098812, 'epoch': 1}
Step 23250: {'loss': 1.1133, 'grad_norm': 7.724044, 'learning_rate': 0.09881, 'epoch': 1}
Step 23300: {'loss': 1.101, 'grad_norm': 8.441218, 'learning_rate': 0.098807, 'epoch': 1}
Step 23350: {'loss': 1.0952, 'grad_norm': 16.087152, 'learning_rate': 0.098804, 'epoch': 1}
Step 23400: {'loss': 1.0572, 'grad_norm': 4.691413, 'learning_rate': 0.098802, 'epoch': 1}
Step 23450: {'loss': 1.0507, 'grad_norm': 3.459595, 'learning_rate': 0.098799, 'epoch': 1}
Step 23500: {'loss': 1.0577, 'grad_norm': 2.594148, 'learning_rate': 0.098797, 'epoch': 1}
Step 23550: {'loss': 1.0566, 'grad_norm': 10.635955, 'learning_rate': 0.098794, 'epoch': 1}
Step 23600: {'loss': 1.0336, 'grad_norm': 3.303749, 'learning_rate': 0.098792, 'epoch': 1}
Step 23650: {'loss': 1.0028, 'grad_norm': 10.884751, 'learning_rate': 0.098789, 'epoch': 1}
Step 23700: {'loss': 1.005, 'grad_norm': 2.547469, 'learning_rate': 0.098787, 'epoch': 1}
Step 23750: {'loss': 0.9726, 'grad_norm': 5.096789, 'learning_rate': 0.098784, 'epoch': 1}
Step 23800: {'loss': 0.9764, 'grad_norm': 3.649109, 'learning_rate': 0.098781, 'epoch': 1}
Step 23850: {'loss': 1.0079, 'grad_norm': 7.519412, 'learning_rate': 0.098779, 'epoch': 1}
Load dataset file 2024-02-13.feather from source
Load dataset sucessfully.
Step 23900: {'loss': 1.0546, 'grad_norm': 6.661765, 'learning_rate': 0.098776, 'epoch': 1}
Step 23950: {'loss': 1.1059, 'grad_norm': 6.56574, 'learning_rate': 0.098774, 'epoch': 1}
Step 24000: {'loss': 1.0756, 'grad_norm': 5.052644, 'learning_rate': 0.098771, 'epoch': 1}
Step 24050: {'loss': 1.0356, 'grad_norm': 6.056797, 'learning_rate': 0.098769, 'epoch': 1}
Step 24100: {'loss': 1.1236, 'grad_norm': 17.488714, 'learning_rate': 0.098766, 'epoch': 1}
Step 24150: {'loss': 1.123, 'grad_norm': 15.00595, 'learning_rate': 0.098764, 'epoch': 1}
Step 24200: {'loss': 1.069, 'grad_norm': 8.134047, 'learning_rate': 0.098761, 'epoch': 1}
Step 24250: {'loss': 1.0366, 'grad_norm': 4.461379, 'learning_rate': 0.098758, 'epoch': 1}
Step 24300: {'loss': 1.0328, 'grad_norm': 9.762967, 'learning_rate': 0.098756, 'epoch': 1}
Step 24350: {'loss': 1.0217, 'grad_norm': 7.363252, 'learning_rate': 0.098753, 'epoch': 1}
Step 24400: {'loss': 0.9896, 'grad_norm': 1.606899, 'learning_rate': 0.098751, 'epoch': 1}
Step 24450: {'loss': 1.0069, 'grad_norm': 2.364784, 'learning_rate': 0.098748, 'epoch': 1}
Step 24500: {'loss': 0.98, 'grad_norm': 1.132059, 'learning_rate': 0.098746, 'epoch': 1}
Step 24550: {'loss': 1.0001, 'grad_norm': 24.999359, 'learning_rate': 0.098743, 'epoch': 1}
Load dataset file 2024-02-14.feather from source
Load dataset sucessfully.
Step 24600: {'loss': 1.0618, 'grad_norm': 8.171181, 'learning_rate': 0.09874, 'epoch': 1}
Step 24650: {'loss': 1.1444, 'grad_norm': 10.116191, 'learning_rate': 0.098738, 'epoch': 1}
Step 24700: {'loss': 1.1422, 'grad_norm': 11.153717, 'learning_rate': 0.098735, 'epoch': 1}
Step 24750: {'loss': 1.1128, 'grad_norm': 17.220728, 'learning_rate': 0.098733, 'epoch': 1}
Step 24800: {'loss': 1.0963, 'grad_norm': 7.240761, 'learning_rate': 0.09873, 'epoch': 1}
Step 24850: {'loss': 1.0668, 'grad_norm': 0.994755, 'learning_rate': 0.098728, 'epoch': 1}
Step 24900: {'loss': 1.07, 'grad_norm': 15.137473, 'learning_rate': 0.098725, 'epoch': 1}
Step 24950: {'loss': 1.0581, 'grad_norm': 3.667622, 'learning_rate': 0.098723, 'epoch': 1}
Step 25000: {'loss': 1.0265, 'grad_norm': 7.826149, 'learning_rate': 0.09872, 'epoch': 1}
Step 25050: {'loss': 1.0404, 'grad_norm': 16.081781, 'learning_rate': 0.098717, 'epoch': 1}
Step 25100: {'loss': 0.9979, 'grad_norm': 3.944792, 'learning_rate': 0.098715, 'epoch': 1}
Step 25150: {'loss': 1.0749, 'grad_norm': 6.198087, 'learning_rate': 0.098712, 'epoch': 1}
Step 25200: {'loss': 0.9746, 'grad_norm': 6.09304, 'learning_rate': 0.09871, 'epoch': 1}
Step 25250: {'loss': 0.9641, 'grad_norm': 7.878973, 'learning_rate': 0.098707, 'epoch': 1}
Load dataset file 2024-02-15.feather from source
Load dataset sucessfully.
Step 25300: {'loss': 1.0768, 'grad_norm': 8.636511, 'learning_rate': 0.098705, 'epoch': 1}
Step 25350: {'loss': 1.1418, 'grad_norm': 9.716902, 'learning_rate': 0.098702, 'epoch': 1}
Step 25400: {'loss': 1.1325, 'grad_norm': 10.397678, 'learning_rate': 0.0987, 'epoch': 1}
Step 25450: {'loss': 1.1252, 'grad_norm': 9.098787, 'learning_rate': 0.098697, 'epoch': 1}
Step 25500: {'loss': 1.1187, 'grad_norm': 13.364245, 'learning_rate': 0.098694, 'epoch': 1}
Step 25550: {'loss': 1.1214, 'grad_norm': 11.78526, 'learning_rate': 0.098692, 'epoch': 1}
Step 25600: {'loss': 1.0936, 'grad_norm': 7.774142, 'learning_rate': 0.098689, 'epoch': 1}
Step 25650: {'loss': 1.0817, 'grad_norm': 8.235204, 'learning_rate': 0.098687, 'epoch': 1}
Step 25700: {'loss': 1.0284, 'grad_norm': 14.923022, 'learning_rate': 0.098684, 'epoch': 1}
2025-02-07 03:50:55.048 | INFO     | Nexus.training.embedder.recommendation.trainer:update_item_vectors:45 - Update item vectors...
2025-02-07 03:55:30.707 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:37 - Model saved in ./saves/ckpt/checkpoint-27440.
2025-02-07 03:55:31.489 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:40 - Item vectors saved to ./saves/ckpt/checkpoint-27440.
2025-02-07 03:55:35.142 | INFO     | Nexus.training.embedder.recommendation.trainer:update_item_vectors:45 - Update item vectors...
2025-02-07 04:00:10.563 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:37 - Model saved in ./saves/ckpt.
2025-02-07 04:00:11.295 | INFO     | Nexus.training.embedder.recommendation.trainer:save_model:40 - Item vectors saved to ./saves/ckpt.
Step 25750: {'loss': 1.041, 'grad_norm': 5.502566, 'learning_rate': 0.098682, 'epoch': 1}
Step 25800: {'loss': 1.0203, 'grad_norm': 6.731512, 'learning_rate': 0.098679, 'epoch': 1}
Step 25850: {'loss': 1.0269, 'grad_norm': 9.268127, 'learning_rate': 0.098676, 'epoch': 1}
Step 25900: {'loss': 1.0482, 'grad_norm': 7.099958, 'learning_rate': 0.098674, 'epoch': 1}
Step 25950: {'loss': 1.0529, 'grad_norm': 13.35387, 'learning_rate': 0.098671, 'epoch': 1}
Step 26000: {'loss': 1.0487, 'grad_norm': 9.400345, 'learning_rate': 0.098669, 'epoch': 1}
Load dataset file 2024-02-16.feather from source
Load dataset sucessfully.
Step 26050: {'loss': 1.1693, 'grad_norm': 4.254824, 'learning_rate': 0.098666, 'epoch': 1}
Step 26100: {'loss': 1.1565, 'grad_norm': 5.400167, 'learning_rate': 0.098664, 'epoch': 1}
Step 26150: {'loss': 1.1279, 'grad_norm': 20.733303, 'learning_rate': 0.098661, 'epoch': 1}
Step 26200: {'loss': 1.1157, 'grad_norm': 13.392486, 'learning_rate': 0.098659, 'epoch': 1}
Step 26250: {'loss': 1.1005, 'grad_norm': 8.307479, 'learning_rate': 0.098656, 'epoch': 1}
Step 26300: {'loss': 1.0945, 'grad_norm': 6.913915, 'learning_rate': 0.098653, 'epoch': 1}
Step 26350: {'loss': 1.0996, 'grad_norm': 11.810683, 'learning_rate': 0.098651, 'epoch': 1}
Step 26400: {'loss': 1.0507, 'grad_norm': 9.592361, 'learning_rate': 0.098648, 'epoch': 1}
Step 26450: {'loss': 1.0585, 'grad_norm': 10.413923, 'learning_rate': 0.098646, 'epoch': 1}
Step 26500: {'loss': 1.0764, 'grad_norm': 7.965385, 'learning_rate': 0.098643, 'epoch': 1}
Step 26550: {'loss': 1.0678, 'grad_norm': 17.768351, 'learning_rate': 0.098641, 'epoch': 1}
Step 26600: {'loss': 1.0558, 'grad_norm': 7.677287, 'learning_rate': 0.098638, 'epoch': 1}
Step 26650: {'loss': 1.0615, 'grad_norm': 5.157387, 'learning_rate': 0.098636, 'epoch': 1}
Step 26700: {'loss': 1.064, 'grad_norm': 18.382812, 'learning_rate': 0.098633, 'epoch': 1}
Load dataset file 2024-02-17.feather from source
Load dataset sucessfully.
Step 26750: {'loss': 1.1016, 'grad_norm': 5.568356, 'learning_rate': 0.09863, 'epoch': 1}
Step 26800: {'loss': 1.1679, 'grad_norm': 7.707979, 'learning_rate': 0.098628, 'epoch': 1}
Step 26850: {'loss': 1.1035, 'grad_norm': 3.980833, 'learning_rate': 0.098625, 'epoch': 1}
Step 26900: {'loss': 1.1238, 'grad_norm': 8.184735, 'learning_rate': 0.098623, 'epoch': 1}
Step 26950: {'loss': 1.1294, 'grad_norm': 8.901655, 'learning_rate': 0.09862, 'epoch': 1}
Step 27000: {'loss': 1.124, 'grad_norm': 11.68735, 'learning_rate': 0.098618, 'epoch': 1}
Step 27050: {'loss': 1.1416, 'grad_norm': 14.590069, 'learning_rate': 0.098615, 'epoch': 1}
Step 27100: {'loss': 1.0953, 'grad_norm': 7.74662, 'learning_rate': 0.098612, 'epoch': 1}
Step 27150: {'loss': 1.0789, 'grad_norm': 9.650062, 'learning_rate': 0.09861, 'epoch': 1}
Step 27200: {'loss': 1.0456, 'grad_norm': 11.720163, 'learning_rate': 0.098607, 'epoch': 1}
Step 27250: {'loss': 1.1448, 'grad_norm': 12.560639, 'learning_rate': 0.098605, 'epoch': 1}
Step 27300: {'loss': 1.0742, 'grad_norm': 7.561395, 'learning_rate': 0.098602, 'epoch': 1}
Step 27350: {'loss': 1.054, 'grad_norm': 9.10254, 'learning_rate': 0.0986, 'epoch': 1}
Step 27400: {'loss': 1.0168, 'grad_norm': 5.241586, 'learning_rate': 0.098597, 'epoch': 1}
Step 27440: {'train_runtime': 14366.1479, 'train_samples_per_second': 69608.082, 'train_steps_per_second': 135.953, 'train_loss': 1.043213, 'epoch': 1}
