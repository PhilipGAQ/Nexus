{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nexus Tutorial for Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key industry features are as follows:\n",
    "\n",
    "- It supports reading data from local and distributed file systems, such as HDFS. Unlike the small-batch datasets used in academia, industrial-level data is often very large and needs to be stored daily in the HDFS distributed file system. Therefore, Nexus provides HDFS data reading interfaces to facilitate rapid integration with industrial scenario data. But it still supports reading data from local files for debugging.\n",
    "\n",
    "- It supports various training configurations including single-machine single-card, single-machine multi-card, and distributed multi-machine multi-card training for the engineer's diverse devlopment needs. The huge amount of industrial data often demands higher training time, so Nexus offers distributed training interfaces to facilitate rapid distributed training of industrial recommendation models. What's more, we utilize the [Accelerate](https://huggingface.co/docs/transformers/accelerate) to wrap the training process. It allows the engineer to switch between training and debugging by modifying a fews lines of code. \n",
    "\n",
    "- It supports easily deploying recommendation models into the industrial internet and severing the customer's request. Nexus contains a high performance inference engine to satisfy the requirements online request's latency. The inference engine compresses the data using [Protocol Buffers](https://github.com/protocolbuffers/protobuf) firstly. It then stores the compressed data into the key-value database [Redis](https://redis.io/). And finally, [ONNX](https://onnx.ai/), [TensorRT](https://github.com/NVIDIA/TensorRT), and [Faiss](https://github.com/facebookresearch/faiss) are integrated into the inference engine to speed up the inference process. \n",
    "\n",
    "The following tutorial will provide a detailed introduction on how to use Nexus for model training, including the following detailed requirements:\n",
    "\n",
    "1. Configuration of training data.\n",
    "2. Model configuration and custom model building.\n",
    "3. Lanuch training under local and distributed environments.\n",
    "4. Saving and reading of models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Configuration\n",
    "\n",
    "Due to the vast amount of data in industrial recommendation systems, distributed systems are often used for storage and retrieval, with HDFS being a commonly used distributed system. Nexus supports storing data in HDFS and using it for training. Below, we will use the RecFlow, an industrial full flow recommendation dataset, published by KuaiShou as an example to illustrate the organization of data.\n",
    "\n",
    "1. Daily Interaction Logs. This part of the data is generally used to record user interactions with items, such as clicks and conversions. Specifically, each time a user refreshes while browsing videos, a request is sent to the system, which is then processed algorithmically. The system is funnel-shaped with multiple stages, ultimately returning 10-20 candidate items to the user, and the user's interactions with these items are fed back into the system, forming a data record. This typically includes: Request ID, User ID, User Features, Item ID, Item Features, User Historical Behavior, Interaction Time, etc. Due to the volume of user data logs, they are often divided into files on a daily basis, such as 2019-07-01.csv, 2019-07-02.csv, etc. In the RecFlow dataset, daily user data logs are stored as YYYY-MM-DD.feather files. [Feather](https://arrow.apache.org/docs/python/feather.html) is a compact file format for storing Arrow tables or data frames and can save lots of storage space. Such logs are mainly used for training and testing of recommendation models.\n",
    "\n",
    "2. Item Corpus Information. This part of the data often includes information of item corpus on the platform, organized in the form of a key-value format, where the key is the item ID and the value is a series of features of the item, such as on a short video platform: the creator of the video, the category of the video, the duration of the video, video tags, etc. It will mostly be utilized for training and inferring of recommendation retrieval models. \n",
    "\n",
    "3. Behavior Sequence Records. This part of the data stores the user's behavior sequence, representing the user's historical interactions, organized in the form of a key-value format, where the key is the request ID and the value is the behavior sequence corresponding to that request ID. We store the user's behavior sequence separately instead of intergrate it with the interaction logs to reduce storage costs. The storage of behavior sequence is heavy and there will exist lots of repeated sequence data if intergrated in interaction logs. The behaivor sequence records play an important role in user modeling and appears in the whole pipeline of industrial recommendation systems.\n",
    "\n",
    "The template for the dataset configuration file is as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"Dataset Name (required)\",\n",
    "    \"type\": \"Dataset type, such as hdfs or file (required)\",\n",
    "    \"url\": \"The location of the dataset interaction data, such as hdfs://ip_address:port/Nexus/recflow/daily_logs (required)\",\n",
    "    \"file_partition\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"Date format, such as %Y-%m-%d. Default is %Y-%m-%d.\"\n",
    "    },\n",
    "    \"item_col\": \"Item ID column name (required)\",\n",
    "    \"item_batch_size\": \"Int, the batch size of item dataloader\",\n",
    "    \"context_features\": [\"List of context (user-side and contextual) features used\", \"Feature 1\", \"Feature 2\", \"(required)\"],\n",
    "    \"item_features\": [\"List of item features used\", \"context_features and item_features must not overlap, both are column names in the main table\", \"(required)\"],\n",
    "    \"labels\": [\"List of labels used\", \"Multiple labels generally indicate multi-task training\", \"The label list must not be empty\", \"(required)\"],\n",
    "    \"filter_settings\": {\n",
    "        \"Filter feature name\": [\"Filter condition 1\", \"Filter condition 2\", \"Filter conditions are in the form of (==, !=, >=, <=, >, <)[number]\"],\n",
    "        \"effective_view\": [\"==1\"],\n",
    "        \"purpose\": \"Generally used for filtering by label, for example, the recall model needs to retain only samples with label=1, and negative samples are sampled from the candidate item set\"\n",
    "    },\n",
    "    \"item_info\": {\n",
    "        \"url\": \"The storage location of the candidate item information data for the recall model, such as hdfs://ip_address:port/Nexus/recflow/others/video_info.pkl, required for recall models\",\n",
    "        \"key\": \"The column name of the item ID. Must be provided for dataframe-style files, not needed for dict-style files\",\n",
    "        \"columns\": [\"Column names of the item feature table, required in item_info, especially for dict file feature naming\"],\n",
    "        \"use_cols\": [\"List of features to be used in item_info, if empty, all columns are used\"]\n",
    "    },\n",
    "    \"user_sequential_info\": [\n",
    "        {\n",
    "            \"name\": \"user sequence name\",\n",
    "            \"url\": \"The storage location of the user sequence data, such as hdfs://ip_address:port/Nexus/recflow/seq_effective_50. Setting user_sequential_info to null indicates that an independent sequence file is not used\",\n",
    "            \"key\": \"The key value for querying sequence data index, such as request_id. This value must also exist in the interaction data table.\",\n",
    "            \"columns\": [\"Column names of the sequence feature table, required in item_info, especially for dict file feature naming, generally the same as or a subset of item_features\"],\n",
    "            \"use_cols\": [\"List of features to be used in user_sequential_info, if empty, all columns are used\"],\n",
    "            \"length\": 50\n",
    "        }\n",
    "    ],\n",
    "    \"stats\": {\n",
    "        \"Feature 1\": 6,\n",
    "        \"Feature 2\": 10,\n",
    "        \"(required)\": \"The cardinality of each feature\"\n",
    "    },\n",
    "    \"train_period\": {\n",
    "        \"start_date\": \"2024-01-13 (required), the start date of the training data\",\n",
    "        \"end_date\": \"2024-02-08, the end date of the training data. Data for this date is not included (required)\"\n",
    "    },\n",
    "    \"test_period\": {\n",
    "        \"start_date\": \"2024-02-08 (required), the start date of the test data\",\n",
    "        \"end_date\": \"2024-02-09, the end date of the test data. Data for this date is not included (required)\"\n",
    "    }\n",
    "    \n",
    "}\n",
    "```\n",
    "\n",
    "Specifically, when the RecFlow dataset is used for training a retriever model, the data configuration is as follows: (It is worth noting that retriever models are often trained only on exposed data, hence the need to set filter_settings)\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"name\": \"recflow\",\n",
    "    \"type\": \"hdfs\",\n",
    "    \"url\": \"hdfs://node1:8020/Nexus/recflow/realshow\",\n",
    "    \"file_partition\": {\n",
    "        \"type\": \"date\",\n",
    "        \"format\": \"%Y-%m-%d\"\n",
    "    },\n",
    "    \"item_col\": \"video_id\",\n",
    "    \"item_batch_size\": 2048,\n",
    "    \"context_features\": [\"user_id\", \"device_id\", \"age\", \"gender\", \"province\"],\n",
    "    \"item_features\": [\"video_id\", \"author_id\", \"category_level_two\", \"upload_type\", \"category_level_one\"],\n",
    "    \"labels\": [\"like\"],\n",
    "    \"filter_settings\": {\n",
    "        \"like\": [\"==1\"]\n",
    "    },\n",
    "    \"item_info\": {\n",
    "        \"url\": \"hdfs://node1:8020/Nexus/recflow/others/video_info.pkl\",\n",
    "        \"key\": \"video_id\",\n",
    "        \"columns\": [\"video_id\", \"author_id\", \"category_level_two\", \"upload_type\", \"upload_timestamp\", \"category_level_one\"],\n",
    "        \"use_cols\": [\"video_id\", \"author_id\", \"category_level_two\", \"upload_type\", \"category_level_one\"]\n",
    "    },\n",
    "    \"user_sequential_info\": [\n",
    "        {\n",
    "            \"name\": \"user_seq_effective_50\",\n",
    "            \"url\": \"hdfs://node1:8020/Nexus/recflow/seq_effective_50\",\n",
    "            \"key\": \"request_id\",\n",
    "            \"columns\": [\"video_id\", \"author_id\", \"category_level_two\", \"category_level_one\", \"upload_type\", \"upload_timestamp\", \"duration\", \"request_timestamp\", \"playing_time\", \"request_id\"],\n",
    "            \"use_cols\": [\"video_id\", \"author_id\", \"category_level_two\", \"category_level_one\", \"upload_type\"],\n",
    "            \"length\": 50\n",
    "        }\n",
    "    ],\n",
    "    \"stats\": {\n",
    "        \"request_id\": 9370581,\n",
    "        \"user_id\": 42472,\n",
    "        \"device_id\": 42561,\n",
    "        \"age\": 8,\n",
    "        \"gender\": 3,\n",
    "        \"province\": 79,\n",
    "        \"video_id\": 82216301,\n",
    "        \"author_id\": 33474011,\n",
    "        \"category_level_one\": 140,\n",
    "        \"category_level_two\": 784,\n",
    "        \"upload_type\": 40\n",
    "    },\n",
    "    \"train_period\": {\n",
    "        \"start_date\": \"2024-02-01\",\n",
    "        \"end_date\": \"2024-02-08\"\n",
    "    },\n",
    "    \"test_period\": {\n",
    "        \"start_date\": \"2024-02-08\",\n",
    "        \"end_date\": \"2024-02-09\"\n",
    "    }\n",
    "    \n",
    "}\n",
    "```\n",
    "\n",
    "With this, the dataset configuration file is complete. Subsequently, Nexus can automatically generate a DataLoader based on the configuration.\n",
    "Before stepping into the details of Nexus, you need to download the data of [RecFlow's learning folder](https://rec.ustc.edu.cn/share/f8e5adc0-2e57-11ef-bea5-3b4cac9d110e) for learning. When downloading, you can put it into your server's local file system or [HDFS](https://hadoop.apache.org/). After you faimilar with Nexus, you can download the whole RecFlow dataset or other recommendation datasets for further research. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration and Building Custom Models\n",
    "This section will describe how to use the models implemented in the library for training and how to inherit base classes to build custom models. Therefore, it will be divided into two subsections for introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, you need to clone Nexus to your local machine and install the dependencies.\n",
    "\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "2. Add Nexus to the Python path to facilitate calling.\n",
    "\n",
    "    ```bash\n",
    "    export PYTHONPATH=$PYTHONPATH:/path/to/Nexus\n",
    "    ```\n",
    "\n",
    "3. Configure the model configuration file, which is used to define the structural parameters of the model, such as embedding size, hidden size, etc. An example is as follows:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"embedding_dim\": 2,\n",
    "        \"num_neg\": 50,\n",
    "        \"mlp_layers\": [64, 64, 8],\n",
    "        \"activation\": \"relu\",\n",
    "        \"dropout\": 0.3,\n",
    "        \"batch_norm\": true\n",
    "    }\n",
    "    ```\n",
    "\n",
    "4. Configure the training parameters, which are used to define the hyperparameters for training, such as batch size, learning rate, etc. An example is as follows:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"num_train_epochs\": 1,\n",
    "        \"max_steps\": 900,\n",
    "        \"per_device_train_batch_size\": 1024,\n",
    "        \"output_dir\": \"./saves/recommender_results/mlp_retriever\",\n",
    "        \"checkpoint_steps\": 150,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"warmup_steps\": 1000\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "For more information on configuration parameters, you can refer to [Configuration Parameters](../../Nexus/training/embedder/recommendation/arguments.py).\n",
    "\n",
    "5. Create a new Python script to import the dataset and model using Nexus and perform training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nexus.training.embedder.recommendation.runner import RetrieverRunner\n",
    "from Nexus.training.embedder.recommendation.modeling import MLPRetriever\n",
    "\n",
    "\n",
    "data_config_path = \"./examples/recommendation/config/data/recflow_retriever.json\"\n",
    "train_config_path = \"./examples/recommendation/config/mlp_retriever/train.json\"\n",
    "model_config_path = \"./examples/recommendation/config/mlp_retriever/model.json\"\n",
    "\n",
    "runner = RetrieverRunner(\n",
    "    model_config_or_path=model_config_path,\n",
    "    data_config_or_path=data_config_path,\n",
    "    train_config_or_path=train_config_path,\n",
    "    model_class=MLPRetriever,\n",
    ")\n",
    "runner.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. At this point, the model training script is complete, and you can run the script to train the model. Executing the script with the Python command will default to single-machine single-GPU training. If you need single-machine multi-GPU or multi-machine multi-GPU training, you can refer to Distributed Training for configuration.\n",
    "\n",
    "    ```bash\n",
    "    python train.py\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will demonstrate how to train custom models by inheriting base classes. We will show the custom usage of recall and ranking models, to illustrate the interfaces that need to be configured for two-tower and single-tower models.\n",
    "\n",
    "First, the first two steps are the same as using built-in models, which require environment setup if you have done so:\n",
    "\n",
    "1. Clone Nexus to your local machine and install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt \n",
    "!pip install -e . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Add Nexus to the Python path to facilitate calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export PYTHONPATH=$PYTHONPATH:/path/to/Nexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retriever Model (Two-tower Model)\n",
    "\n",
    "3. Import the BaseRetriever class and inherit from it to implement your custom model. A recall model is typically composed of four main modules:\n",
    "\n",
    "- query_encoder: The context (query) feature encoder, which encodes user and context features into vector representations.\n",
    "- item_encoder: The item feature encoder, which encodes item features into vector representations.\n",
    "- score_function: The scoring function, which calculates the match degree between user-item pairs.\n",
    "- loss_function: The loss function, which calculates the difference between the model's predicted values and the true labels.\n",
    "\n",
    "Therefore, you need to override the following methods. The configuration parameters required when defining the model structure come from the model.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from Nexus.training.embedder.recommendation.modeling import BaseRetriever\n",
    "from Nexus.modules.arguments import get_modules\n",
    "from Nexus.modules.embedding import MultiFeatEmbedding\n",
    "from Nexus.modules.layer import MLPModule\n",
    "\n",
    "class MYMLPRetriever(BaseRetriever):\n",
    "    def __init__(self, config, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "\n",
    "    def get_item_encoder(self):\n",
    "        item_emb = MultiFeatEmbedding(\n",
    "            features=self.data_config.item_features,\n",
    "            stats=self.data_config.stats,\n",
    "            embedding_dim=self.model_config.embedding_dim,\n",
    "            concat_embeddings=True\n",
    "        )\n",
    "        mlp = MLPModule(\n",
    "            mlp_layers= [item_emb.total_embedding_dim] + self.model_config.mlp_layers,\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "        return torch.nn.Sequential(OrderedDict([\n",
    "            (\"item_embedding\", item_emb),\n",
    "            (\"mlp\", mlp)\n",
    "            ]))\n",
    "    \n",
    "\n",
    "    def get_query_encoder(self):\n",
    "        context_emb = MultiFeatEmbedding(\n",
    "            features=self.data_config.context_features,\n",
    "            stats=self.data_config.stats,\n",
    "            embedding_dim=self.model_config.embedding_dim\n",
    "        )\n",
    "        base_encoder = get_modules(\"encoder\", \"BaseQueryEncoderWithSeq\")(\n",
    "            context_embedding=context_emb,\n",
    "            item_encoder=self.item_encoder\n",
    "        )\n",
    "        output_dim = self.model_config.mlp_layers[-1] + context_emb.total_embedding_dim\n",
    "        mlp = MLPModule(\n",
    "            mlp_layers= [output_dim] + self.model_config.mlp_layers,\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "\n",
    "        return torch.nn.Sequential(OrderedDict([\n",
    "            (\"encoder\", base_encoder),\n",
    "            (\"mlp\", mlp)\n",
    "            ]))\n",
    "\n",
    "    def get_score_function(self):\n",
    "        return get_modules(\"score\", \"InnerProductScorer\")()\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        return get_modules(\"loss\", \"BPRLoss\")()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "4. After implementing your custom recall model by inheriting from BaseRetriever, the process of creating a training script using Nexus is similar to that of training built-in models. You will need to utilize the dataset, model, and training configuration files to quickly complete the training script. Here's a step-by-step guide to help you set up your training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "from Nexus.training.embedder.recommendation.runner import RetrieverRunner\n",
    "\n",
    "\n",
    "data_config_path = \"./config/data/recflow_retriever.json\"\n",
    "train_config_path = \"./config/mlp_retriever/train.json\"\n",
    "model_config_path = \"./config/mlp_retriever/model.json\"\n",
    "\n",
    "runner = RetrieverRunner(\n",
    "    model_config_path=model_config_path,\n",
    "    data_config_path=data_config_path,\n",
    "    train_config_path=train_config_path,\n",
    "    model_class=MYMLPRetriever,\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranker Model\n",
    "\n",
    "Unlike retriever models, ranker models typically focus on the interaction between features and the combination of features. Therefore, the functions that need to be overridden are different, and the modules that need to be built include:\n",
    "\n",
    "- Sequence Feature Aggregator: Used to aggregate a feature sequence of shape (L,D) into a single feature of shape (D) for subsequent feature interaction.\n",
    "- Feature Interaction Module: Used to interact a series of features, usually the single feature output by the Sequence Feature Aggregator. Common modules include MLP, FM, etc.\n",
    "- Prediction Module: Used for the final prediction after feature interaction, typically a fully connected layer, following the feature interaction module.\n",
    "- Loss Function: Used to calculate the loss between predicted values and true labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Import the BaseRanker class and inherit from the BaseRanker class to implement a custom model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Nexus.training.reranker.recommendation.modeling import BaseRanker\n",
    "from Nexus.modules.arguments import get_modules\n",
    "from Nexus.modules.layer import MLPModule, LambdaModule\n",
    "\n",
    "\n",
    "\n",
    "class MYMLPRanker(BaseRanker):\n",
    "    def get_sequence_encoder(self):\n",
    "        cls = get_modules(\"module\", \"AverageAggregator\")\n",
    "        encoder = cls(dim=1)\n",
    "        return encoder\n",
    "    \n",
    "    def get_feature_interaction_layer(self):\n",
    "        flatten_layer = LambdaModule(lambda x: x.flatten(start_dim=1))  # [B, N, D] -> [B, N*D]\n",
    "        mlp_layer = MLPModule(\n",
    "            mlp_layers= [self.num_feat * self.model_config.embedding_dim] + self.model_config.mlp_layers,\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "        return torch.nn.Sequential(flatten_layer, mlp_layer)\n",
    "    \n",
    "    def get_prediction_layer(self):\n",
    "        pred_mlp = MLPModule(\n",
    "            mlp_layers=[self.model_config.mlp_layers[-1]] + self.model_config.prediction_layers + [1],\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "        return pred_mlp\n",
    "\n",
    "    def get_loss_function(self):\n",
    "        return get_modules(\"loss\", \"BCEWithLogitLoss\")(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Then, consistent with training built-in models, by using the dataset, model, and training configuration file, you can quickly complete the training script with Nexus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "from Nexus.training.reranker.recommendation.runner import RankerRunner\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_config_path = \"./config/data/recflow_ranker.json\"\n",
    "    train_config_path = \"./config/mlp_ranker/train.json\"\n",
    "    model_config_path = \"./config/mlp_ranker/model.json\"\n",
    "    \n",
    "    runner = RankerRunner(\n",
    "        model_config_path=model_config_path,\n",
    "        data_config_path=data_config_path,\n",
    "        train_config_path=train_config_path,\n",
    "        model_class=MYMLPRanker\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Machine Training and Distributed Multi-Machine Training of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nexus supports basic single-machine single-GPU training, single-machine multi-GPU training, and distributed training.\n",
    "\n",
    "1. Single-machine single-GPU training: Directly start with the Python command or start with `accelerate` command (the configuration file of accelerate refer to [single_gpu.json](config/distributed_training/single_gpu.json)).\n",
    "\n",
    "   ```shell\n",
    "   # start with Python command\n",
    "   CUDA_VISIBLE_DEVICES=1 python main.py\n",
    "   # start with accelerate command\n",
    "   accelerate launch --config_file single_gpu.json main.py\n",
    "   ```\n",
    "\n",
    "2. Single-machine multi-GPU training: First, configure for single-machine multi-GPU, refer to the example file [configuration file single_node.json](config/distributed_training/single_node.json). Then start with the accelerate command.\n",
    "\n",
    "    ```shell\n",
    "    accelerate launch --config_file single_node.json main.py\n",
    "    ```\n",
    "\n",
    "    Note that multi-GPU training on a single machine will by default occupy port 29500 on the local machine. If you need to run multiple tasks, you need to specify different port numbers in the command or in the JSON file: --main_process_port 29501 (specified in the command line) or \"main_process_port\": 29501 (JSON file).\n",
    "\n",
    "    In addition, the current training methods for both single-machine multi-GPU and multi-machine multi-GPU environments adopt DistributedDataParallel (DDP). During the training process, each process will save a complete model and optimizer on the corresponding GPU. Additionally, each GPU maintains a \"bucket\" to gather gradients from other GPUs during training. Therefore, during model preparation, twice the model size of GPU memory overhead will be occupied than training with a single GPU. For more details, please refer to: [blog1](https://discuss.pytorch.org/t/memory-consumption-for-the-model-get-doubled-after-wrapped-with-ddp/130837), [blog2](https://medium.com/deep-learning-for-protein-design/a-comprehensive-guide-to-memory-usage-in-pytorch-b9b7c78031d3).\n",
    "\n",
    "3. Multi-machine multi-GPU distributed training:\n",
    "    - Configure the environment on multiple machines, download Nexus, and install dependencies.\n",
    "    - Configure for multi-machine multi-GPU on each machine, refer to the example files [configuration file multi_node_rank0.json](config/distributed_training/multi_nodes_rank0.json) and [configuration file multi_node_rank1.json](config/distributed_training/multi_nodes_rank1.json). Then start with the accelerate command on the rank0 machine first, and then start the other machines in sequence:\n",
    "    \n",
    "    ```shell\n",
    "    accelerate launch --config_file multi_node_rank0.json main.py\n",
    "    ```\n",
    "\n",
    "\n",
    "Note:\n",
    "All the acclerate configuration files mentioned above are created by `accelerate config` command.\n",
    "\n",
    "```shell\n",
    "accelerate config --config_file xxx.json\n",
    "```\n",
    "\n",
    "The you need to select the corresponding options according to your needs in an interactive way.\n",
    "For more details, please refer to the [accelerate](https://github.com/huggingface/accelerate) documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "In an online recommendation system, handling a single request typically involves the following steps:\n",
    "- **Receiving the request header**: The request header includes the user ID and context-specific features (e.g., location and timestamp of the request).\n",
    "- **Obtaining the Candidate Item Set**: At each stage, the recommendation model receives the candidate item set from the previous stage (for the retrieval model, it is the entire item pool).\n",
    "- **Retrieving Features**: At each stage, the system retrieves user- and item-related features required by the recommendation model based on the user ID and candidate item IDs. To enable fast access, user and item features are stored in a cache database (e.g., Redis) in a key-value format.\n",
    "- **Sorting the Candidate Item Set**: At each stage, the recommendation model ranks the candidate items using the retrieved features and selects the top-k items to pass to the next stage (for the final stage, the top-k items are directly presented to the user)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Features in Cache Database\n",
    "### Defining message in protobuf\n",
    "To reduce the cache size occupied by features, Protobuf is used to serialize the features before storing them in the cache database. To use Protobuf,  message data structures must first be defined.\n",
    "\n",
    "In the .proto file, the user and item message data structures are defined. For example, in recflow.proto:\n",
    "\n",
    "Each feature of user and item is treated as a field of the message structure."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# the version of protobuf\n",
    "\n",
    "syntax = \"proto3\"; \n",
    "\n",
    "package example;\n",
    "\n",
    "message Item {\n",
    "  int64 video_id = 1;\n",
    "  int64 author_id = 2;\n",
    "  int64 category_level_two = 3;\n",
    "  int64 upload_type = 4;\n",
    "  int64 upload_timestamp = 5;\n",
    "  int64 category_level_one = 6;\n",
    "  int64 request_timestamp = 7; \n",
    "}\n",
    "\n",
    "message UserTimestamp {\n",
    "  int64 request_id = 1;          \n",
    "  int64 user_id = 2;             \n",
    "  int64 request_timestamp = 3;    \n",
    "  int64 device_id = 4;           \n",
    "  int32 age = 5;                  \n",
    "  int64 gender = 6;              \n",
    "  int64 province = 7;\n",
    "  repeated Item seq_effective_50 = 8;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, generate Python code from the .proto file using protoc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create proto\n",
    "protoc --python_out=. ./inference/feature_insert/protos/recflow.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Features into Redis Database\n",
    "When storing user-side or item-side features in a Redis database, the process typically involves several steps:\n",
    "\n",
    "​\t1.\tCreate a message object.\n",
    "\n",
    "​\t2.\tAssign values to each field of the message object.\n",
    "\n",
    "​\t3.\tSerialize the message object.\n",
    "\n",
    "​\t4.\tStore the serialized message object in the Redis database. The key is usually set as {dataset_name}:{object_name}:{object_primary_key}.\n",
    "\n",
    "An example of inserting features into the Redis database using recflow is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "\n",
    "import recflow_pb2\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Item\n",
    "test_video_info = pd.read_feather('./inference/feature_data/recflow/realshow_test_video_info.feather')\n",
    "for row in tqdm(test_video_info.itertuples(), total=len(test_video_info)):\n",
    "\n",
    "    # 0. Create a message object\n",
    "    item = recflow_pb2.Item()\n",
    "    item.video_id = getattr(row, 'video_id')\n",
    "    item.author_id = getattr(row, 'author_id')\n",
    "    item.category_level_two = getattr(row, '_3')\n",
    "    item.upload_type = getattr(row, 'upload_type')\n",
    "    item.upload_timestamp = getattr(row, 'upload_timestamp')\n",
    "    item.category_level_one = getattr(row, 'category_level_one')\n",
    "    \n",
    "    # 1. Serialize the Protobuf object into binary data\n",
    "    serialized_data = item.SerializeToString()\n",
    "\n",
    "    # 2. Store the compressed data in Redis\n",
    "    r.set(f\"recflow:item:{item.video_id}\", serialized_data)\n",
    "    \n",
    "\n",
    "print(\"Item features are stored in Redis.\")\n",
    "\n",
    "# User\n",
    "test_user_info = np.load('./inference/feature_data/recflow/test_user_info.npz')['arr_0']\n",
    "for row in tqdm(test_user_info):\n",
    "\n",
    "    # 0. Create a message object \n",
    "    user_timestamp = recflow_pb2.UserTimestamp()\n",
    "    user_timestamp.request_id = row[0]\n",
    "    user_timestamp.user_id = row[1]\n",
    "    user_timestamp.request_timestamp = row[2]\n",
    "    user_timestamp.device_id = row[3]\n",
    "    user_timestamp.age = row[4]\n",
    "    user_timestamp.gender = row[5]\n",
    "    user_timestamp.province = row[6]\n",
    "    \n",
    "    for behavior in np.split(test_user_info[0][7:], len(test_user_info[0][7:]) // 6):\n",
    "        item = user_timestamp.seq_effective_50.add()\n",
    "        item.video_id = behavior[0]\n",
    "        item.author_id = behavior[1]\n",
    "        item.category_level_two = behavior[2]\n",
    "        item.category_level_one = behavior[3]\n",
    "        item.upload_type = behavior[4]\n",
    "        item.request_timestamp = behavior[5]\n",
    "\n",
    "    # 1. Serialize the Protobuf object into binary data\n",
    "    serialized_data = user_timestamp.SerializeToString()\n",
    "\n",
    "    # 2. Store the compressed data in Redis\n",
    "    r.set(f\"recflow:user_timestamp:{row[1]}_{row[2]}\", serialized_data)\n",
    "\n",
    "print(\"UserTimestamp features are stored in Redis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cache configuration file `feature_cache_config.yaml`\n",
    "\n",
    "To enable the use of features stored in the cache, we need to generate a configuration file `feature_cache_config.yaml` for each dataset.\n",
    "\n",
    "Taking Recflow as an example:\n",
    "\n",
    "The `host`, `port`, and `db` fields specify details of Redis database. `features`  specifies the storage details for each feature. Within `features`, `key_temp` represents the key template for the feature in Redis database, where the content inside {} is replaced with specific item or user information, and `field` specifies the attribute name of the feature in the message object. `key_temp2proto` maps each key template to the corresponding message class name, which is used to create message objects."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "host: localhost\n",
    "port: 6379\n",
    "db: 0\n",
    "features:\n",
    "  video_id:\n",
    "    key_temp: recflow:item:{video_id}\n",
    "    field: video_id\n",
    "  author_id:\n",
    "    key_temp: recflow:item:{video_id}\n",
    "    field: author_id\n",
    "  category_level_two:\n",
    "    key_temp: recflow:item:{video_id}\n",
    "    field: category_level_two\n",
    "...\n",
    "  request_id:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: request_id\n",
    "  user_id:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: user_id\n",
    "  request_timestamp:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: request_timestamp\n",
    "...\n",
    "  seq_effective_50:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: seq_effective_50\n",
    "key_temp2proto:\n",
    "  recflow:item:{video_id}:\n",
    "    class_name: Item\n",
    "    module_path: ./inference/feature_insert/protos/recflow_pb2.py\n",
    "  recflow:user_timestamp:{user_id}_{request_timestamp}:\n",
    "    class_name: UserTimestamp\n",
    "    module_path: ./inference/feature_insert/protos/recflow_pb2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running ./inference/feature_insert/recflow_script/run.sh completes the three steps mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InferenceEngine\n",
    "\n",
    "[InferenceEngine](../../UniRetrieval/abc/inference/inference_engine.py) class can be initialized to perform the inference process. By inheriting InferenceEngine, we further define BaseEmbedderInferenceEngine and BaseRerankerInferenceEngine and use them for inference\n",
    "\n",
    "1. Converting a checkpoint of the recommendation model to an `onnxruntime.InferenceSession`.\n",
    "2.\tPerforming batch inference.\n",
    "3.\tOutputting the top-k candidate items.\n",
    "\n",
    "We can initialize the InferenceEngine class and perform batch inference as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from Nexus.inference.embedder.recommendation import BaseEmbedderInferenceEngine\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "infer_config_path = \"/data1/home/recstudio/haoran/Nexus/examples/recommendation/inference/config/recflow_infer_retrieval_config.yaml\"\n",
    "\n",
    "with open(infer_config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "retriever_inference_engine = BaseEmbedderInferenceEngine(config)\n",
    "\n",
    "    \n",
    "infer_df = pd.read_feather('/data1/home/recstudio/haoran/Nexus/examples/recommendation/inference/inference_data/recflow/recflow_infer_data.feather')\n",
    "for batch_idx in range(10):\n",
    "    print(f\"This is batch {batch_idx}\")\n",
    "    batch_st = batch_idx * 128 \n",
    "    batch_ed = (batch_idx + 1) * 128 \n",
    "    batch_infer_df = infer_df.iloc[batch_st:batch_ed]\n",
    "    retriever_outputs = retriever_inference_engine.batch_inference(batch_infer_df)\n",
    "    print(type(retriever_outputs), retriever_outputs.shape, retriever_outputs)\n",
    "if retriever_inference_engine.config['infer_mode'] == 'trt':\n",
    "    cuda.Context.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from Nexus.inference.reranker.recommendation import BaseRerankerInferenceEngine\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "\n",
    "infer_config_path = \"./examples/recommendation/inference/config/recflow_infer_ranker_config.yaml\"\n",
    "\n",
    "with open(infer_config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    print(config)\n",
    "\n",
    "rank_inference_engine = BaseRerankerInferenceEngine(config)\n",
    "    \n",
    "infer_df = pd.read_feather('/data1/home/recstudio/haoran/Nexus/examples/recommendation/inference/inference_data/recflow/recflow_infer_data.feather')\n",
    "item_df = pd.read_feather('/data1/home/recstudio/haoran/Nexus/examples/recommendation/inference/inference_data/recflow/realshow_test_video_info.feather')\n",
    "all_item_ids = np.array(item_df['video_id'])\n",
    "for batch_idx in range(10):\n",
    "    print(f\"This is batch {batch_idx}\")\n",
    "    batch_st = batch_idx * 128 \n",
    "    batch_ed = (batch_idx + 1) * 128 \n",
    "    batch_infer_df = infer_df.iloc[batch_st:batch_ed]\n",
    "    np.random.seed(42)\n",
    "    batch_candidates = np.random.choice(all_item_ids, size=(128, 50))\n",
    "    batch_candidates_df = pd.DataFrame({rank_inference_engine.feature_config['fiid']: batch_candidates.tolist()})\n",
    "    ranker_outputs = rank_inference_engine.batch_inference(batch_infer_df, batch_candidates_df)\n",
    "    print(type(ranker_outputs), ranker_outputs.shape, ranker_outputs[-5:])\n",
    "    \n",
    "if rank_inference_engine.config['infer_mode'] == 'trt':\n",
    "    cuda.Context.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support onnx and tensorrt for inference acceleration. You only need to adjust the infer_mode parameter in [config.yaml](./inference/config/recflow_infer_ranker_config.yaml) to \"ort\" or \"trt\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We designed [RecommenderAbsEvaluator](../../UniRetrieval/evaluation/recommendation/evaluator.py) to evaluate model checkpoints. During the evaluation process, it is necessary to provide [eval_config.json](./eval/eval_config.json) and [eval_model_config.json](./eval/eval_model_config.json) to configure certain evaluation hyperparameters, evaluation dataset paths, checkpoint paths, and other related settings. Then, use these configs to initialize a [RecommenderEvalRunner](../../UniRetrieval/evaluation/recommendation/runner.py) class, and you can simply call the run() function to perform the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Nexus.evaluation.recommendation import RecommenderEvalArgs, RecommenderEvalModelArgs, RecommenderEvalRunner\n",
    "\n",
    "eval_config_path = \"./examples/recommendation/eval/eval_config.json\"\n",
    "model_config_path = \"./examples/recommendation/eval/eval_model_config.json\"\n",
    "\n",
    "eval_args = RecommenderEvalArgs.from_json(eval_config_path)\n",
    "model_args = RecommenderEvalModelArgs.from_json(model_config_path)\n",
    "    \n",
    "runner = RecommenderEvalRunner(\n",
    "    eval_args=eval_args,\n",
    "    model_args=model_args\n",
    ")\n",
    "\n",
    "runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recstudio_industry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
