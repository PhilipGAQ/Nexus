{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples for Recommendation\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Configure the data configuration file, which is used to define the parameters of the training dataset, such as item column, context_features, etc. An example is as follows:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"name\": \"recflow\",\n",
    "        \"type\": \"hdfs\",\n",
    "        \"url\": \"hdfs://node1:8020/recstudio/recflow/realshow\",\n",
    "        \"item_col\": \"video_id\",\n",
    "        \"context_features\": [\"user_id\", \"device_id\", \"age\", \"gender\", \"province\"],\n",
    "        \"labels\": [\"like\"],\n",
    "        \"item_batch_size\": 4096,\n",
    "        \"filter_settings\": {\n",
    "            \"like\": [\"==1\"]\n",
    "        },\n",
    "        \"item_info\": {\n",
    "            \"url\": \"hdfs://node1:8020/recstudio/recflow/others/video_info.pkl\",\n",
    "            \"key\": \"video_id\",\n",
    "            \"columns\": [\"video_id\", \"author_id\", \"category_level_two\", \"upload_type\", \"upload_timestamp\", \"category_level_one\"],\n",
    "            \"use_cols\": [\"video_id\", \"author_id\", \"category_level_two\", \"upload_type\", \"category_level_one\"]\n",
    "        },\n",
    "        \"user_sequential_info\": {\n",
    "            \"url\": \"hdfs://node1:8020/recstudio/recflow/seq_effective_50\",\n",
    "            \"key\": \"request_id\",\n",
    "            \"columns\": [\"video_id\", \"author_id\", \"category_level_two\", \"category_level_one\", \"upload_type\", \"upload_timestamp\", \"duration\", \"request_timestamp\", \"playing_time\", \"request_id\"],\n",
    "            \"use_cols\": [\"video_id\", \"author_id\", \"category_level_two\", \"category_level_one\", \"upload_type\"]\n",
    "        },\n",
    "        \"stats\": {\n",
    "            \"request_id\": 9370581,\n",
    "            \"user_id\": 42472,\n",
    "            \"device_id\": 42561,\n",
    "            \"age\": 8,\n",
    "            \"gender\": 3,\n",
    "            \"province\": 79,\n",
    "            \"video_id\": 82216301,\n",
    "            \"author_id\": 33474011,\n",
    "            \"category_level_one\": 140,\n",
    "            \"category_level_two\": 784,\n",
    "            \"upload_type\": 40\n",
    "        },\n",
    "        \"train_settings\": {\n",
    "            \"start_date\": \"2024-02-08\",\n",
    "            \"end_date\": \"2024-02-09\"\n",
    "        },\n",
    "        \"test_settings\": {\n",
    "            \"start_date\": \"2024-02-08\",\n",
    "            \"end_date\": \"2024-02-09\"\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "\n",
    "2. Configure the model configuration file, which is used to define the structural parameters of the model, such as embedding size, hidden size, etc. An example is as follows:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"embedding_dim\": 4,\n",
    "        \"mlp_layers\": [128, 128],\n",
    "        \"prediction_layers\": [32],\n",
    "        \"activation\": \"relu\",\n",
    "        \"dropout\": 0.1,\n",
    "        \"batch_norm\": false\n",
    "    }\n",
    "    ```\n",
    "\n",
    "3. Configure the training parameters, which are used to define the hyperparameters for training, such as batch size, learning rate, etc. An example is as follows:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"epochs\": 1,\n",
    "        \"train_batch_size\": 2048,\n",
    "        \"eval_batch_size\": 4096,\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"learning_rate\": 1e-2,\n",
    "        \"checkpoint_dir\": \"path_to_save_checkpoint\",\n",
    "        \"checkpoint_steps\": 1000,\n",
    "        \"evaluation_strategy\": \"epoch\",\n",
    "        \"eval_interval\": 1,\n",
    "        \"metrics\": [\"auc\", \"logloss\"],\n",
    "        \"earlystop_metric\": \"auc\"\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "3. Create a new Python script to import the dataset and model and perform training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "from UniRetrieval.training.embedder.recommendation.runner import RetrieverRunner\n",
    "from UniRetrieval.training.embedder.recommendation.modeling import MLPRetriever\n",
    "\n",
    "\n",
    "data_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/data/recflow_retriever.json\"\n",
    "train_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/mlp_retriever/train.json\"\n",
    "model_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/mlp_retriever/model.json\"\n",
    "\n",
    "runner = RetrieverRunner(\n",
    "    model_config_path=model_config_path,\n",
    "    data_config_path=data_config_path,\n",
    "    train_config_path=train_config_path,\n",
    "    model_class=MLPRetriever,\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. At this point, the model training script is complete, and you can run the script to train the model. Executing the script with the Python command will default to single-machine single-GPU training. If you need single-machine multi-GPU or multi-machine multi-GPU training, you can refer to Distributed Training for configuration.\n",
    "\n",
    "    ```bash\n",
    "    python train.py\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will demonstrate how to train custom models by inheriting base classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "#### Retriever Model\n",
    "\n",
    "1. Import the BaseRetriever class and inherit from it to implement your custom model. A recall model is typically composed of four main modules:\n",
    "\n",
    "- query_encoder: The context (query) feature encoder, which encodes user and context features into vector representations.\n",
    "- item_encoder: The item feature encoder, which encodes item features into vector representations.\n",
    "- score_function: The scoring function, which calculates the match degree between user-item pairs.\n",
    "- loss_function: The loss function, which calculates the difference between the model's predicted values and the true labels.\n",
    "\n",
    "Therefore, you need to override the following methods. The configuration parameters required when defining the model structure come from the model.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from UniRetrieval.training.embedder.recommendation.modeling import BaseRetriever\n",
    "from UniRetrieval.modules.arguments import get_modules\n",
    "from UniRetrieval.modules.embedding import MultiFeatEmbedding\n",
    "from UniRetrieval.modules.layer import MLPModule\n",
    "\n",
    "class MYMLPRetriever(BaseRetriever):\n",
    "    def __init__(self, config, *args, **kwargs):\n",
    "        super().__init__(config, *args, **kwargs)\n",
    "\n",
    "    def get_item_encoder(self):\n",
    "        item_emb = MultiFeatEmbedding(\n",
    "            features=self.data_config.item_features,\n",
    "            stats=self.data_config.stats,\n",
    "            embedding_dim=self.model_config.embedding_dim,\n",
    "            concat_embeddings=True\n",
    "        )\n",
    "        mlp = MLPModule(\n",
    "            mlp_layers= [item_emb.total_embedding_dim] + self.model_config.mlp_layers,\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "        return torch.nn.Sequential(OrderedDict([\n",
    "            (\"item_embedding\", item_emb),\n",
    "            (\"mlp\", mlp)\n",
    "            ]))\n",
    "    \n",
    "\n",
    "    def get_query_encoder(self):\n",
    "        context_emb = MultiFeatEmbedding(\n",
    "            features=self.data_config.context_features,\n",
    "            stats=self.data_config.stats,\n",
    "            embedding_dim=self.model_config.embedding_dim\n",
    "        )\n",
    "        base_encoder = get_modules(\"encoder\", \"BaseQueryEncoderWithSeq\")(\n",
    "            context_embedding=context_emb,\n",
    "            item_encoder=self.item_encoder\n",
    "        )\n",
    "        output_dim = self.model_config.mlp_layers[-1] + context_emb.total_embedding_dim\n",
    "        mlp = MLPModule(\n",
    "            mlp_layers= [output_dim] + self.model_config.mlp_layers,\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "\n",
    "        return torch.nn.Sequential(OrderedDict([\n",
    "            (\"encoder\", base_encoder),\n",
    "            (\"mlp\", mlp)\n",
    "            ]))\n",
    "\n",
    "    def get_score_function(self):\n",
    "        return get_modules(\"score\", \"InnerProductScorer\")()\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        return get_modules(\"loss\", \"BPRLoss\")()\n",
    "    \n",
    "    def get_negative_sampler(self):\n",
    "        sampler_cls = get_modules(\"sampler\", \"UniformSampler\")\n",
    "        return sampler_cls(num_items=self.data_config.num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "2. After implementing your custom recall model by inheriting from BaseRetriever, the process of creating a training script using UniRetrieval is similar to that of training built-in models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "from UniRetrieval.training.embedder.recommendation.runner import RetrieverRunner\n",
    "\n",
    "\n",
    "data_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/data/recflow_retriever.json\"\n",
    "train_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/mlp_retriever/train.json\"\n",
    "model_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/mlp_retriever/model.json\"\n",
    "\n",
    "runner = RetrieverRunner(\n",
    "    model_config_path=model_config_path,\n",
    "    data_config_path=data_config_path,\n",
    "    train_config_path=train_config_path,\n",
    "    model_class=MYMLPRetriever,\n",
    ")\n",
    "runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranker Model\n",
    "\n",
    "Unlike retriever models, ranker models typically focus on the interaction between features and the combination of features. Therefore, the functions that need to be overridden are different, and the modules that need to be built include:\n",
    "\n",
    "- Sequence Feature Aggregator: Used to aggregate a feature sequence of shape (L,D) into a single feature of shape (D) for subsequent feature interaction.\n",
    "- Feature Interaction Module: Used to interact a series of features, usually the single feature output by the Sequence Feature Aggregator. Common modules include MLP, FM, etc.\n",
    "- Prediction Module: Used for the final prediction after feature interaction, typically a fully connected layer, following the feature interaction module.\n",
    "- Loss Function: Used to calculate the loss between predicted values and true labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Import the BaseRanker class and inherit from the BaseRanker class to implement a custom model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from UniRetrieval.training.reranker.recommendation.modeling import BaseRanker\n",
    "from UniRetrieval.modules.arguments import get_modules\n",
    "from UniRetrieval.modules.layer import MLPModule, LambdaModule\n",
    "\n",
    "\n",
    "\n",
    "class MYMLPRanker(BaseRanker):\n",
    "    def get_sequence_encoder(self):\n",
    "        cls = get_modules(\"module\", \"AverageAggregator\")\n",
    "        encoder = cls(dim=1)\n",
    "        return encoder\n",
    "    \n",
    "    def get_feature_interaction_layer(self):\n",
    "        flatten_layer = LambdaModule(lambda x: x.flatten(start_dim=1))  # [B, N, D] -> [B, N*D]\n",
    "        mlp_layer = MLPModule(\n",
    "            mlp_layers= [self.num_feat * self.model_config.embedding_dim] + self.model_config.mlp_layers,\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "        return torch.nn.Sequential(flatten_layer, mlp_layer)\n",
    "    \n",
    "    def get_prediction_layer(self):\n",
    "        pred_mlp = MLPModule(\n",
    "            mlp_layers=[self.model_config.mlp_layers[-1]] + self.model_config.prediction_layers + [1],\n",
    "            activation_func=self.model_config.activation,\n",
    "            dropout=self.model_config.dropout,\n",
    "            bias=True,\n",
    "            batch_norm=self.model_config.batch_norm,\n",
    "            last_activation=False,\n",
    "            last_bn=False\n",
    "        )\n",
    "        return pred_mlp\n",
    "\n",
    "    def get_loss_function(self):\n",
    "        return get_modules(\"loss\", \"BCEWithLogitLoss\")(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Then, consistent with training built-in models, by using the dataset, model, and training configuration file, you can quickly complete the training script with UniRetrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "from UniRetrieval.training.reranker.recommendation.runner import RankerRunner\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/data/recflow_ranker.json\"\n",
    "    train_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/mlp_ranker/train.json\"\n",
    "    model_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/config/mlp_ranker/model.json\"\n",
    "    \n",
    "    runner = RankerRunner(\n",
    "        model_config_path=model_config_path,\n",
    "        data_config_path=data_config_path,\n",
    "        train_config_path=train_config_path,\n",
    "        model_class=MYMLPRanker\n",
    "    )\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Machine Training and Distributed Multi-Machine Training of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UniRetrieval supports basic single-machine single-GPU training, single-machine multi-GPU training, and distributed training\n",
    "\n",
    "1. Single-machine single-GPU training: Directly start with the Python command or start with `accelerate` command (the configuration file of accelerate refer to [single_gpu.json](config/distributed_training/single_gpu.json)).\n",
    "\n",
    "   ```shell\n",
    "   # start with Python command\n",
    "   CUDA_VISIBLE_DEVICES=1 python main.py\n",
    "   # start with accelerate command\n",
    "   accelerate launch --config_file single_gpu.json main.py\n",
    "   ```\n",
    "\n",
    "2. Single-machine multi-GPU training: First, configure for single-machine multi-GPU, refer to the example file [configuration file single_node.json](config/distributed_training/single_node.json). Then start with the accelerate command.\n",
    "\n",
    "    ```shell\n",
    "    accelerate launch --config_file single_node.json main.py\n",
    "    ```\n",
    "\n",
    "    Note that multi-GPU training on a single machine will by default occupy port 29500 on the local machine. If you need to run multiple tasks, you need to specify different port numbers in the command or in the JSON file: --main_process_port 29501 (specified in the command line) or \"main_process_port\": 29501 (JSON file).\n",
    "\n",
    "    In addition, the current training methods for both single-machine multi-GPU and multi-machine multi-GPU environments adopt DistributedDataParallel (DDP). During the training process, each process will save a complete model and optimizer on the corresponding GPU. Additionally, each GPU maintains a \"bucket\" to gather gradients from other GPUs during training. Therefore, during model preparation, twice the model size of GPU memory overhead will be occupied than training with a single GPU. For more details, please refer to: [blog1](https://discuss.pytorch.org/t/memory-consumption-for-the-model-get-doubled-after-wrapped-with-ddp/130837), [blog2](https://medium.com/deep-learning-for-protein-design/a-comprehensive-guide-to-memory-usage-in-pytorch-b9b7c78031d3).\n",
    "\n",
    "3. Multi-machine multi-GPU distributed training:\n",
    "    - Configure the environment on multiple machines, download UniRetrieval, and install dependencies.\n",
    "    - Configure for multi-machine multi-GPU on each machine, refer to the example files [configuration file multi_node_rank0.json](config/distributed_training/multi_nodes_rank0.json) and [configuration file multi_node_rank1.json](config/distributed_training/multi_nodes_rank1.json). Then start with the accelerate command on the rank0 machine first, and then start the other machines in sequence:\n",
    "    \n",
    "    ```shell\n",
    "    accelerate launch --config_file multi_node_rank0.json main.py\n",
    "    ```\n",
    "\n",
    "\n",
    "Note:\n",
    "All the acclerate configuration files mentioned above are created by `accelerate config` command.\n",
    "\n",
    "```shell\n",
    "accelerate config --config_file xxx.json\n",
    "```\n",
    "\n",
    "The you need to select the corresponding options according to your needs in an interactive way.\n",
    "For more details, please refer to the [accelerate](https://github.com/huggingface/accelerate) documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "In an online recommendation system, handling a single request typically involves the following steps:\n",
    "- **Receiving the request header**: The request header includes the user ID and context-specific features (e.g., location and timestamp of the request).\n",
    "- **Obtaining the Candidate Item Set**: At each stage, the recommendation model receives the candidate item set from the previous stage (for the retrieval model, it is the entire item pool).\n",
    "- **Retrieving Features**: At each stage, the system retrieves user- and item-related features required by the recommendation model based on the user ID and candidate item IDs. To enable fast access, user and item features are stored in a cache database (e.g., Redis) in a key-value format.\n",
    "- **Sorting the Candidate Item Set**: At each stage, the recommendation model ranks the candidate items using the retrieved features and selects the top-k items to pass to the next stage (for the final stage, the top-k items are directly presented to the user)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Features in Cache Database\n",
    "### Defining message in protobuf\n",
    "To reduce the cache size occupied by features, Protobuf is used to serialize the features before storing them in the cache database. To use Protobuf,  message data structures must first be defined.\n",
    "\n",
    "In the .proto file, the user and item message data structures are defined. For example, in recflow.proto:\n",
    "\n",
    "Each feature of user and item is treated as a field of the message structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the version of protobuf\n",
    "\n",
    "syntax = \"proto3\"; \n",
    "\n",
    "package example;\n",
    "\n",
    "message Item {\n",
    "  int64 video_id = 1;\n",
    "  int64 author_id = 2;\n",
    "  int64 category_level_two = 3;\n",
    "  int64 upload_type = 4;\n",
    "  int64 upload_timestamp = 5;\n",
    "  int64 category_level_one = 6;\n",
    "  int64 request_timestamp = 7; \n",
    "}\n",
    "\n",
    "message UserTimestamp {\n",
    "  int64 request_id = 1;          \n",
    "  int64 user_id = 2;             \n",
    "  int64 request_timestamp = 3;    \n",
    "  int64 device_id = 4;           \n",
    "  int32 age = 5;                  \n",
    "  int64 gender = 6;              \n",
    "  int64 province = 7;\n",
    "  repeated Item seq_effective_50 = 8;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, generate Python code from the .proto file using protoc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create proto\n",
    "protoc --python_out=. ./inference/feature_insert/protos/recflow.proto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Features into Redis Database\n",
    "When storing user-side or item-side features in a Redis database, the process typically involves several steps:\n",
    "\n",
    "​\t1.\tCreate a message object.\n",
    "\n",
    "​\t2.\tAssign values to each field of the message object.\n",
    "\n",
    "​\t3.\tSerialize the message object.\n",
    "\n",
    "​\t4.\tStore the serialized message object in the Redis database. The key is usually set as {dataset_name}:{object_name}:{object_primary_key}.\n",
    "\n",
    "An example of inserting features into the Redis database using recflow is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "\n",
    "import recflow_pb2\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Item\n",
    "test_video_info = pd.read_feather('./inference/feature_data/recflow/realshow_test_video_info.feather')\n",
    "for row in tqdm(test_video_info.itertuples(), total=len(test_video_info)):\n",
    "\n",
    "    # 0. Create a message object\n",
    "    item = recflow_pb2.Item()\n",
    "    item.video_id = getattr(row, 'video_id')\n",
    "    item.author_id = getattr(row, 'author_id')\n",
    "    item.category_level_two = getattr(row, '_3')\n",
    "    item.upload_type = getattr(row, 'upload_type')\n",
    "    item.upload_timestamp = getattr(row, 'upload_timestamp')\n",
    "    item.category_level_one = getattr(row, 'category_level_one')\n",
    "    \n",
    "    # 1. Serialize the Protobuf object into binary data\n",
    "    serialized_data = item.SerializeToString()\n",
    "\n",
    "    # 2. Store the compressed data in Redis\n",
    "    r.set(f\"recflow:item:{item.video_id}\", serialized_data)\n",
    "    \n",
    "\n",
    "print(\"Item features are stored in Redis.\")\n",
    "\n",
    "# User\n",
    "test_user_info = np.load('./inference/feature_data/recflow/test_user_info.npz')['arr_0']\n",
    "for row in tqdm(test_user_info):\n",
    "\n",
    "    # 0. Create a message object \n",
    "    user_timestamp = recflow_pb2.UserTimestamp()\n",
    "    user_timestamp.request_id = row[0]\n",
    "    user_timestamp.user_id = row[1]\n",
    "    user_timestamp.request_timestamp = row[2]\n",
    "    user_timestamp.device_id = row[3]\n",
    "    user_timestamp.age = row[4]\n",
    "    user_timestamp.gender = row[5]\n",
    "    user_timestamp.province = row[6]\n",
    "    \n",
    "    for behavior in np.split(test_user_info[0][7:], len(test_user_info[0][7:]) // 6):\n",
    "        item = user_timestamp.seq_effective_50.add()\n",
    "        item.video_id = behavior[0]\n",
    "        item.author_id = behavior[1]\n",
    "        item.category_level_two = behavior[2]\n",
    "        item.category_level_one = behavior[3]\n",
    "        item.upload_type = behavior[4]\n",
    "        item.request_timestamp = behavior[5]\n",
    "\n",
    "    # 1. Serialize the Protobuf object into binary data\n",
    "    serialized_data = user_timestamp.SerializeToString()\n",
    "\n",
    "    # 2. Store the compressed data in Redis\n",
    "    r.set(f\"recflow:user_timestamp:{row[1]}_{row[2]}\", serialized_data)\n",
    "\n",
    "print(\"UserTimestamp features are stored in Redis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cache configuration file `feature_cache_config.yaml`\n",
    "\n",
    "To enable the use of features stored in the cache, we need to generate a configuration file `feature_cache_config.yaml` for each dataset.\n",
    "\n",
    "Taking Recflow as an example:\n",
    "\n",
    "The `host`, `port`, and `db` fields specify details of Redis database. `features`  specifies the storage details for each feature. Within `features`, `key_temp` represents the key template for the feature in Redis database, where the content inside {} is replaced with specific item or user information, and `field` specifies the attribute name of the feature in the message object. `key_temp2proto` maps each key template to the corresponding message class name, which is used to create message objects."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "host: localhost\n",
    "port: 6379\n",
    "db: 0\n",
    "features:\n",
    "  video_id:\n",
    "    key_temp: recflow:item:{video_id}\n",
    "    field: video_id\n",
    "  author_id:\n",
    "    key_temp: recflow:item:{video_id}\n",
    "    field: author_id\n",
    "  category_level_two:\n",
    "    key_temp: recflow:item:{video_id}\n",
    "    field: category_level_two\n",
    "...\n",
    "  request_id:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: request_id\n",
    "  user_id:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: user_id\n",
    "  request_timestamp:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: request_timestamp\n",
    "...\n",
    "  seq_effective_50:\n",
    "    key_temp: recflow:user_timestamp:{user_id}_{request_timestamp}\n",
    "    field: seq_effective_50\n",
    "key_temp2proto:\n",
    "  recflow:item:{video_id}:\n",
    "    class_name: Item\n",
    "    module_path: ./inference/feature_insert/protos/recflow_pb2.py\n",
    "  recflow:user_timestamp:{user_id}_{request_timestamp}:\n",
    "    class_name: UserTimestamp\n",
    "    module_path: ./inference/feature_insert/protos/recflow_pb2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running ./inference/feature_insert/recflow_script/run.sh completes the three steps mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InferenceEngine\n",
    "\n",
    "[InferenceEngine](../../UniRetrieval/abc/inference/inference_engine.py) class can be initialized to perform the inference process. By inheriting InferenceEngine, we further define BaseEmbedderInferenceEngine and BaseRerankerInferenceEngine and use them for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from UniRetrieval.inference.embedder.recommendation import BaseEmbedderInferenceEngine\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "infer_config_path = \"/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/inference/config/recflow_infer_retrieval_config.yaml\"\n",
    "\n",
    "with open(infer_config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "retriever_inference_engine = BaseEmbedderInferenceEngine(config)\n",
    "\n",
    "infer_df = pd.read_feather('/data1/home/recstudio/haoran/RecStudio-Industry/inference/inference_data/recflow/recflow_infer_data.feather')\n",
    "for batch_idx in range(10):\n",
    "    print(f\"This is batch {batch_idx}\")\n",
    "    batch_st = batch_idx * 128 \n",
    "    batch_ed = (batch_idx + 1) * 128 \n",
    "    batch_infer_df = infer_df.iloc[batch_st:batch_ed]\n",
    "    retriever_outputs = retriever_inference_engine.batch_inference(batch_infer_df)\n",
    "    print(type(retriever_outputs), retriever_outputs.shape)\n",
    "if retriever_inference_engine.config['infer_mode'] == 'trt':\n",
    "    cuda.Context.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference: Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from UniRetrieval.inference.reranker.recommendation import BaseRerankerInferenceEngine\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "\n",
    "infer_config_path = \"/data1/home/recstudio/haoran/angqing_temp/mlp_reranker/recflow_infer_ranker_config.yaml\"\n",
    "\n",
    "with open(infer_config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    print(config)\n",
    "\n",
    "rank_inference_engine = BaseRerankerInferenceEngine(config)\n",
    "\n",
    "\n",
    "infer_df = pd.read_feather('/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/inference/inference_data/recflow/recflow_infer_data.feather')\n",
    "item_df = pd.read_feather('/data1/home/recstudio/haoran/UniRetrieval/examples/recommendation/inference/inference_data/recflow/realshow_test_video_info.feather')\n",
    "all_item_ids = np.array(item_df['video_id'])\n",
    "for batch_idx in range(10):\n",
    "    print(f\"This is batch {batch_idx}\")\n",
    "    batch_st = batch_idx * 128 \n",
    "    batch_ed = (batch_idx + 1) * 128 \n",
    "    batch_infer_df = infer_df.iloc[batch_st:batch_ed]\n",
    "    batch_candidates = np.random.choice(all_item_ids, size=(128, 50))\n",
    "    batch_candidates_df = pd.DataFrame({rank_inference_engine.feature_config['fiid']: batch_candidates.tolist()})\n",
    "    ranker_outputs = rank_inference_engine.batch_inference(batch_infer_df, batch_candidates_df)\n",
    "    print(type(ranker_outputs), ranker_outputs.shape)\n",
    "    \n",
    "if rank_inference_engine.config['infer_mode'] == 'trt':\n",
    "    cuda.Context.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support onnx and tensorrt for inference acceleration. You only need to adjust the infer_mode parameter in config to ort or trt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recstudio_industry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
