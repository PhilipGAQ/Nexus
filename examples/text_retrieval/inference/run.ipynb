{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniRetrieval import FlagModel, AbsInferenceArguments, BaseEmbedderInferenceEngine\n",
    "\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"The Eiffel Tower is located in Paris, France.\",\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"The Great Wall of China is one of the Seven Wonders of the World.\",\n",
    "    \"Space exploration has led to many scientific discoveries.\",\n",
    "    \"Climate change is a pressing global issue.\",\n",
    "    \"The Mona Lisa is a famous painting by Leonardo da Vinci.\",\n",
    "    \"Electric cars are becoming more common.\",\n",
    "    \"The human brain is an incredibly complex organ.\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "model = FlagModel(model_name_or_path='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5', use_fp16=True, devices=['cuda:1','cuda:0']) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "emb_model= model.encode(sentences, batch_size = 5)\n",
    "\n",
    "print(emb_model.shape)\n",
    "print(emb_model[0]@ emb_model[1].T)\n",
    "# 2. using inference engine\n",
    "model_path='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5'\n",
    "args=AbsInferenceArguments(\n",
    "    model_name_or_path=model_path,\n",
    "    infer_mode='normal',\n",
    "    infer_device=0,\n",
    "    infer_batch_size=16\n",
    ")\n",
    "args.infer_mode='normal'\n",
    "inference_engine=BaseEmbedderInferenceEngine(args)\n",
    "emb_normal=inference_engine.inference(sentences, batch_size=10, normalize=True)\n",
    "print(emb_normal.shape)\n",
    "print(emb_normal[0]@ emb_normal[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniRetrieval import AbsInferenceArguments, BaseEmbedderInferenceEngine\n",
    "model_path='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5'\n",
    "onnx_model_path='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5/onnx/model.onnx'\n",
    "BaseEmbedderInferenceEngine.convert_to_onnx(model_name_or_path=model_path, onnx_model_path=onnx_model_path)\n",
    "\n",
    "# 2. Inference with onnx session\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"The Eiffel Tower is located in Paris, France.\",\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"The Great Wall of China is one of the Seven Wonders of the World.\",\n",
    "    \"Space exploration has led to many scientific discoveries.\",\n",
    "    \"Climate change is a pressing global issue.\",\n",
    "    \"The Mona Lisa is a famous painting by Leonardo da Vinci.\",\n",
    "    \"Electric cars are becoming more common.\",\n",
    "    \"The human brain is an incredibly complex organ.\"\n",
    "]\n",
    "\n",
    "args=AbsInferenceArguments(\n",
    "    model_name_or_path=model_path,\n",
    "    onnx_model_path=onnx_model_path,\n",
    "    trt_model_path=None,\n",
    "    infer_mode='onnx',\n",
    "    infer_device=0,\n",
    "    infer_batch_size=16\n",
    ")\n",
    "inference_engine_onnx = BaseEmbedderInferenceEngine(args)\n",
    "emb_onnx = inference_engine_onnx.inference(sentences, normalize=True, batch_size=5)\n",
    "print(emb_onnx.shape)\n",
    "print(emb_onnx[0]@ emb_onnx[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniRetrieval import AbsInferenceArguments, BaseEmbedderInferenceEngine\n",
    "model_path='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5'\n",
    "trt_model_path ='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5/trt/model.trt'\n",
    "onnx_model_path='/data1/home/recstudio/angqing/models/bge-base-zh-v1.5/onnx/model.onnx'\n",
    "\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world.\",\n",
    "    \"The Eiffel Tower is located in Paris, France.\",\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"The Great Wall of China is one of the Seven Wonders of the World.\",\n",
    "    \"Space exploration has led to many scientific discoveries.\",\n",
    "    \"Climate change is a pressing global issue.\",\n",
    "    \"The Mona Lisa is a famous painting by Leonardo da Vinci.\",\n",
    "    \"Electric cars are becoming more common.\",\n",
    "    \"The human brain is an incredibly complex organ.\"\n",
    "]\n",
    "\n",
    "args=AbsInferenceArguments(\n",
    "    model_name_or_path=model_path,\n",
    "    onnx_model_path=onnx_model_path,\n",
    "    trt_model_path=trt_model_path,\n",
    "    infer_mode='tensorrt',\n",
    "    infer_device=0,\n",
    "    infer_batch_size=16\n",
    ")\n",
    "inference_engine_tensorrt=BaseEmbedderInferenceEngine(args)\n",
    "emb_trt=inference_engine_tensorrt.inference(sentences, normalize=True, batch_size=5)\n",
    "print(emb_trt.shape)\n",
    "print(emb_trt[0]@ emb_trt[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniRetrieval import FlagReranker, AbsInferenceArguments, BaseRerankerInferenceEngine\n",
    "\n",
    "# inputs should be Union[Tuple, List[Tuple]]\n",
    "qa_pairs = [\n",
    "    (\"What is the capital of France?\", \"Paris is the capital and most populous city of France.\"),\n",
    "    (\"Who wrote 'Pride and Prejudice'?\",\"Edison wrote this.\" ),\n",
    "    (\"What is the largest planet in our solar system?\", \"May be our mother land.\"),\n",
    "    (\"Who is the current president of the United States?\", \"The current president of the United States is Joe Biden.\"),\n",
    "    (\"What is the chemical symbol for water?\", \"The chemical symbol for water is H2O.\"),\n",
    "    (\"What is the speed of light?\", \"The speed of light is approximately 299,792 kilometers per second.\"),\n",
    "    (\"Who painted the Mona Lisa?\", \"The Mona Lisa was painted by Leonardo da Vinci.\"),\n",
    "    (\"What is the tallest mountain in the world?\", \"Mount Everest is the tallest mountain in the world.\"),\n",
    "    (\"What is the smallest country in the world?\", \"Vatican City is the smallest country in the world.\"),\n",
    "    (\"Who discovered penicillin?\", \"Penicillin was discovered by Alexander Fleming.\")\n",
    "]\n",
    "\n",
    "model_name_or_path= '/data1/home/recstudio/angqing/models/bge-reranker-base'\n",
    "\n",
    "model = FlagReranker(model_name_or_path=model_name_or_path, normalize=True, use_fp16=True, devices=['cuda:0']) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "score = model.compute_score(qa_pairs)\n",
    "print(score)\n",
    "# 2. using inference engine\n",
    "args=AbsInferenceArguments(\n",
    "    model_name_or_path=model_name_or_path,\n",
    "    infer_mode='normal',\n",
    "    infer_device=0,\n",
    "    infer_batch_size=16\n",
    ")\n",
    "args.infer_mode = 'normal'\n",
    "inference_engine = BaseRerankerInferenceEngine(args)\n",
    "score = inference_engine.inference(qa_pairs, batch_size=10, normalize=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniRetrieval import AbsInferenceArguments, BaseRerankerInferenceEngine\n",
    "model_path='/data1/home/recstudio/angqing/models/bge-reranker-base'\n",
    "onnx_model_path='/data1/home/recstudio/angqing/models/bge-reranker-base/onnx/model.onnx'\n",
    "BaseRerankerInferenceEngine.convert_to_onnx(model_name_or_path=model_path, onnx_model_path=onnx_model_path)\n",
    "\n",
    "# inputs should be Union[Tuple, List[Tuple]]\n",
    "qa_pairs = [\n",
    "    (\"What is the capital of France?\", \"Paris is the capital and most populous city of France.\"),\n",
    "    (\"Who wrote 'Pride and Prejudice'?\",\"Edison wrote this.\" ),\n",
    "    (\"What is the largest planet in our solar system?\", \"May be our mother land.\"),\n",
    "    (\"Who is the current president of the United States?\", \"The current president of the United States is Joe Biden.\"),\n",
    "    (\"What is the chemical symbol for water?\", \"The chemical symbol for water is H2O.\"),\n",
    "    (\"What is the speed of light?\", \"The speed of light is approximately 299,792 kilometers per second.\"),\n",
    "    (\"Who painted the Mona Lisa?\", \"The Mona Lisa was painted by Leonardo da Vinci.\"),\n",
    "    (\"What is the tallest mountain in the world?\", \"Mount Everest is the tallest mountain in the world.\"),\n",
    "    (\"What is the smallest country in the world?\", \"Vatican City is the smallest country in the world.\"),\n",
    "    (\"Who discovered penicillin?\", \"Penicillin was discovered by Alexander Fleming.\")\n",
    "]\n",
    "# 2. Inference with onnx session\n",
    "args=AbsInferenceArguments(\n",
    "    model_name_or_path=model_path,\n",
    "    onnx_model_path=onnx_model_path,\n",
    "    trt_model_path=None,\n",
    "    infer_mode='onnx',\n",
    "    infer_device=0,\n",
    "    infer_batch_size=16\n",
    ")\n",
    "inference_engine_onnx = BaseRerankerInferenceEngine(args)\n",
    "score = inference_engine_onnx.inference(qa_pairs, normalize=True, batch_size=5)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UniRetrieval import AbsInferenceArguments, BaseRerankerInferenceEngine\n",
    "model_path='/data1/home/recstudio/angqing/models/bge-reranker-base'\n",
    "onnx_model_path='/data1/home/recstudio/angqing/models/bge-reranker-base/onnx/model.onnx'\n",
    "trt_model_path='/data1/home/recstudio/angqing/models/bge-reranker-base/trt/model.trt'\n",
    "\n",
    "qa_pairs = [\n",
    "    (\"What is the capital of France?\", \"Paris is the capital and most populous city of France.\"),\n",
    "    (\"Who wrote 'Pride and Prejudice'?\",\"Edison wrote this.\" ),\n",
    "    (\"What is the largest planet in our solar system?\", \"May be our mother land.\"),\n",
    "    (\"Who is the current president of the United States?\", \"The current president of the United States is Joe Biden.\"),\n",
    "    (\"What is the chemical symbol for water?\", \"The chemical symbol for water is H2O.\"),\n",
    "    (\"What is the speed of light?\", \"The speed of light is approximately 299,792 kilometers per second.\"),\n",
    "    (\"Who painted the Mona Lisa?\", \"The Mona Lisa was painted by Leonardo da Vinci.\"),\n",
    "    (\"What is the tallest mountain in the world?\", \"Mount Everest is the tallest mountain in the world.\"),\n",
    "    (\"What is the smallest country in the world?\", \"Vatican City is the smallest country in the world.\"),\n",
    "    (\"Who discovered penicillin?\", \"Penicillin was discovered by Alexander Fleming.\")\n",
    "]\n",
    "\n",
    "args=AbsInferenceArguments(\n",
    "    model_name_or_path=model_path,\n",
    "    onnx_model_path=onnx_model_path,\n",
    "    trt_model_path=trt_model_path,\n",
    "    infer_mode='tensorrt',\n",
    "    infer_device=0,\n",
    "    infer_batch_size=16\n",
    ")\n",
    "inference_engine_tensorrt = BaseRerankerInferenceEngine(args)\n",
    "score = inference_engine_tensorrt.inference(qa_pairs, normalize=True, batch_size=5)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
